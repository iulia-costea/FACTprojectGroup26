{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google UX Designer Binary Classification Analysis (Table 1 Reproduction)\n",
    "\n",
    "This notebook reproduces the binary classification results from Section 8 of the paper for the Google UX Designer role.\n",
    "\n",
    "We will test three conditions:\n",
    "1. **U: No LLMs, P: GPT-4O** - Unprivileged group has no LLM access, Privileged group uses GPT-4o\n",
    "2. **U: GPT-3.5, P: GPT-4O** - Unprivileged uses GPT-3.5, Privileged uses GPT-4o  \n",
    "3. **U: GPT-4O-MINI, P: GPT-4O** - Unprivileged uses GPT-4o-mini, Privileged uses GPT-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Merge Qualified and Unqualified Resume Scores\n",
    "\n",
    "- **Qualified**: UX designer resumes (n=260) - these ARE qualified for the UX role\n",
    "- **Unqualified**: PM resumes (n=260) - these are NOT qualified for the UX role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualified resumes: 260\n",
      "Unqualified resumes: 260\n",
      "\n",
      "Qualified sample:\n",
      "   Unnamed: 0  CV Google_UX Score  UX True Label\n",
      "0           0              84.209              1\n",
      "1           1              84.209              1\n",
      "2           2              85.607              1\n",
      "3           3              80.387              1\n",
      "4           4              88.592              1\n",
      "\n",
      "Unqualified sample:\n",
      "   Unnamed: 0  CV Google_UX Score  UX True Label\n",
      "0           0              78.228              0\n",
      "1           1              81.609              0\n",
      "2           2              79.725              0\n",
      "3           3              80.315              0\n",
      "4           4              82.063              0\n"
     ]
    }
   ],
   "source": [
    "# Load qualified resumes (UX designers)\n",
    "qualified_original = pd.read_csv('../tpr_calculation_files/Qualified_UX/ScoresGoogle_UX_Original_File.csv')\n",
    "qualified_original['UX True Label'] = 1  # Qualified for UX role\n",
    "\n",
    "# Load unqualified resumes (PM resumes)\n",
    "unqualified_original = pd.read_csv('../tpr_calculation_files/Unqualified_UX/ScoresGoogle_UX_Original_File_pm_resumes.csv')\n",
    "unqualified_original['UX True Label'] = 0  # Unqualified for UX role\n",
    "\n",
    "print(f\"Qualified resumes: {len(qualified_original)}\")\n",
    "print(f\"Unqualified resumes: {len(unqualified_original)}\")\n",
    "print(\"\\nQualified sample:\")\n",
    "print(qualified_original.head())\n",
    "print(\"\\nUnqualified sample:\")\n",
    "print(unqualified_original.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load All Modified Resume Scores\n",
    "\n",
    "We need to load scores for:\n",
    "- GPT-3.5 modified\n",
    "- GPT-4o modified (once)\n",
    "- GPT-4o-mini modified\n",
    "- GPT-4o on GPT-3.5 (twice modified)\n",
    "- GPT-4o on GPT-4o-mini (twice modified)\n",
    "- GPT-4o on GPT-4o (twice modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All score files loaded successfully!\n",
      "Each file has 260 qualified and 260 unqualified resumes\n"
     ]
    }
   ],
   "source": [
    "# Load GPT-3.5 modified scores\n",
    "qualified_gpt35 = pd.read_csv('../tpr_calculation_files/Qualified_UX/ScoresGoogle_UX_gpt35turbo.csv')\n",
    "unqualified_gpt35 = pd.read_csv('../tpr_calculation_files/Unqualified_UX/ScoresGoogle_UX_gpt35turbo.csv')\n",
    "\n",
    "# Load GPT-4o modified scores (once)\n",
    "qualified_gpt4o = pd.read_csv('../tpr_calculation_files/Qualified_UX/ScoresGoogle_UX_gpt4o.csv')\n",
    "unqualified_gpt4o = pd.read_csv('../tpr_calculation_files/Unqualified_UX/ScoresGoogle_UX_gpt4o.csv')\n",
    "\n",
    "# Load GPT-4o-mini modified scores\n",
    "qualified_gpt4omini = pd.read_csv('../tpr_calculation_files/Qualified_UX/ScoresGoogle_UX_gpt4omini.csv')\n",
    "unqualified_gpt4omini = pd.read_csv('../tpr_calculation_files/Unqualified_UX/ScoresGoogle_UX_gpt4omini.csv')\n",
    "\n",
    "# Load GPT-4o on GPT-3.5 scores\n",
    "qualified_gpt4o_on_gpt35 = pd.read_csv('../tpr_calculation_files/Qualified_UX/ScoresGoogle_UX_gpt4o_on_gpt35turbo.csv')\n",
    "unqualified_gpt4o_on_gpt35 = pd.read_csv('../tpr_calculation_files/Unqualified_UX/ScoresGoogle_UX_gpt4o_on_gpt35turbo.csv')\n",
    "\n",
    "# Load GPT-4o on GPT-4o-mini scores\n",
    "qualified_gpt4o_on_gpt4omini = pd.read_csv('../tpr_calculation_files/Qualified_UX/ScoresGoogle_UX_gpt4o_on_gpt4omini.csv')\n",
    "unqualified_gpt4o_on_gpt4omini = pd.read_csv('../tpr_calculation_files/Unqualified_UX/ScoresGoogle_UX_gpt4o_ongpt4omini.csv')\n",
    "\n",
    "# Load GPT-4o on GPT-4o scores (twice modified)\n",
    "qualified_gpt4o_on_gpt4o = pd.read_csv('../tpr_calculation_files/Qualified_UX/ScoresGoogle_UX_gpt4o_on_gpt4o.csv')\n",
    "unqualified_gpt4o_on_gpt4o = pd.read_csv('../tpr_calculation_files/Unqualified_UX/ScoresGoogle_UX_gpt4o_on_gpt4o.csv')\n",
    "\n",
    "print(\"All score files loaded successfully!\")\n",
    "print(f\"Each file has {len(qualified_gpt35)} qualified and {len(unqualified_gpt35)} unqualified resumes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Merge All Scores into Single Dataframe\n",
    "\n",
    "We'll create one dataframe with all score columns for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataframe shape: (520, 9)\n",
      "Total resumes: 520\n",
      "\n",
      "Columns: ['Unnamed: 0', 'CV Google_UX Score', 'UX True Label', 'GPT-3.5 Score', 'GPT-4o Score', 'GPT-4o-mini Score', 'GPT-4o on GPT-3.5 Score', 'GPT-4o on GPT-4o-mini Score', 'GPT-4o on GPT-4o Score']\n",
      "\n",
      "Sample data:\n",
      "   Unnamed: 0  CV Google_UX Score  UX True Label  GPT-3.5 Score  GPT-4o Score  \\\n",
      "0           0              84.209              1         84.666        83.219   \n",
      "1           1              84.209              1         85.905        85.236   \n",
      "2           2              85.607              1         89.395        89.270   \n",
      "3           3              80.387              1         81.141        82.108   \n",
      "4           4              88.592              1         86.736        87.710   \n",
      "\n",
      "   GPT-4o-mini Score  GPT-4o on GPT-3.5 Score  GPT-4o on GPT-4o-mini Score  \\\n",
      "0             83.438                   85.864                       82.949   \n",
      "1             84.554                   86.135                       83.910   \n",
      "2             86.999                   88.006                       87.201   \n",
      "3             81.209                   85.642                       82.076   \n",
      "4             89.356                   85.511                       88.883   \n",
      "\n",
      "   GPT-4o on GPT-4o Score  \n",
      "0                  82.927  \n",
      "1                  84.678  \n",
      "2                  89.360  \n",
      "3                  85.693  \n",
      "4                  87.158  \n",
      "\n",
      "Label distribution:\n",
      "UX True Label\n",
      "1    260\n",
      "0    260\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge qualified scores\n",
    "qualified_df = qualified_original.copy()\n",
    "qualified_df['GPT-3.5 Score'] = qualified_gpt35.iloc[:, 1]  # Second column has the scores\n",
    "qualified_df['GPT-4o Score'] = qualified_gpt4o.iloc[:, 1]\n",
    "qualified_df['GPT-4o-mini Score'] = qualified_gpt4omini.iloc[:, 1]\n",
    "qualified_df['GPT-4o on GPT-3.5 Score'] = qualified_gpt4o_on_gpt35.iloc[:, 1]\n",
    "qualified_df['GPT-4o on GPT-4o-mini Score'] = qualified_gpt4o_on_gpt4omini.iloc[:, 1]\n",
    "qualified_df['GPT-4o on GPT-4o Score'] = qualified_gpt4o_on_gpt4o.iloc[:, 1]\n",
    "\n",
    "# Merge unqualified scores\n",
    "unqualified_df = unqualified_original.copy()\n",
    "unqualified_df['GPT-3.5 Score'] = unqualified_gpt35.iloc[:, 1]\n",
    "unqualified_df['GPT-4o Score'] = unqualified_gpt4o.iloc[:, 1]\n",
    "unqualified_df['GPT-4o-mini Score'] = unqualified_gpt4omini.iloc[:, 1]\n",
    "unqualified_df['GPT-4o on GPT-3.5 Score'] = unqualified_gpt4o_on_gpt35.iloc[:, 1]\n",
    "unqualified_df['GPT-4o on GPT-4o-mini Score'] = unqualified_gpt4o_on_gpt4omini.iloc[:, 1]\n",
    "unqualified_df['GPT-4o on GPT-4o Score'] = unqualified_gpt4o_on_gpt4o.iloc[:, 1]\n",
    "\n",
    "# Combine qualified and unqualified\n",
    "df_combined = pd.concat([qualified_df, unqualified_df], ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataframe shape: {df_combined.shape}\")\n",
    "print(f\"Total resumes: {len(df_combined)}\")\n",
    "print(f\"\\nColumns: {df_combined.columns.tolist()}\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(df_combined.head())\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_combined['UX True Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Randomly Assign \"Will Manipulate\" Groups\n",
    "\n",
    "Randomly assign 260 resumes to Privileged group (P, Will Manipulate=True) and 260 to Unprivileged group (U, Will Manipulate=False).\n",
    "\n",
    "This assignment is independent of whether the resume is qualified or unqualified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will Manipulate distribution:\n",
      "Will Manipulate\n",
      "True     260\n",
      "False    260\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cross-tabulation of True Label vs Will Manipulate:\n",
      "Will Manipulate  False  True \n",
      "UX True Label                \n",
      "0                  135    125\n",
      "1                  125    135\n",
      "\n",
      "Sample of data with new column:\n",
      "   CV Google_UX Score  UX True Label  Will Manipulate\n",
      "0              84.209              1             True\n",
      "1              84.209              1            False\n",
      "2              85.607              1             True\n",
      "3              80.387              1             True\n",
      "4              88.592              1            False\n",
      "5              85.647              1             True\n",
      "6              84.062              1             True\n",
      "7              82.276              1             True\n",
      "8              88.742              1            False\n",
      "9              84.935              1             True\n"
     ]
    }
   ],
   "source": [
    "# Randomly assign Will Manipulate groups (50/50 split)\n",
    "# Use a fixed random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "indices = np.arange(len(df_combined))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# First 260 get Will Manipulate = True, next 260 get False\n",
    "df_combined['Will Manipulate'] = False\n",
    "df_combined.loc[indices[:260], 'Will Manipulate'] = True\n",
    "\n",
    "# Verify the assignment\n",
    "print(\"Will Manipulate distribution:\")\n",
    "print(df_combined['Will Manipulate'].value_counts())\n",
    "print(\"\\nCross-tabulation of True Label vs Will Manipulate:\")\n",
    "print(pd.crosstab(df_combined['UX True Label'], df_combined['Will Manipulate']))\n",
    "print(\"\\nSample of data with new column:\")\n",
    "print(df_combined[['CV Google_UX Score', 'UX True Label', 'Will Manipulate']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Complete!\n",
    "\n",
    "We now have a complete dataset with:\n",
    "- **520 resumes total** (260 qualified UX + 260 unqualified PM)\n",
    "- **True labels**: UX True Label (1=qualified, 0=unqualified)\n",
    "- **Group assignment**: Will Manipulate (True=Privileged group P, False=Unprivileged group U)\n",
    "- **7 score columns**: Original, GPT-3.5, GPT-4o, GPT-4o-mini, GPT-4o on GPT-3.5, GPT-4o on GPT-4o-mini, GPT-4o on GPT-4o\n",
    "\n",
    "Next steps: Define the three experimental conditions and run the binary classification analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Helper Functions\n",
    "\n",
    "These functions replicate the methodology from the paper:\n",
    "1. **Score mapping functions**: Map original and modified scores based on group assignment\n",
    "2. **Threshold calculation**: Find optimal threshold with No False Positives objective\n",
    "3. **Metrics calculation**: Calculate TPR, FNR, Accuracy, and Disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Function 1: Map input scores (Traditional 1-ticket scheme)\n",
    "def map_input_score(row, group, groups_dict):\n",
    "    \"\"\"\n",
    "    Maps the score that the applicant submits to the hiring system.\n",
    "    - If Will Manipulate = True (Privileged): returns max(original, privileged_LLM_score)\n",
    "    - If Will Manipulate = False (Unprivileged): returns max(original, unprivileged_LLM_score)\n",
    "    \"\"\"\n",
    "    if row['Will Manipulate']:\n",
    "        # Privileged group: choose best between original and their LLM (Input-B)\n",
    "        return max(row[groups_dict[group]['Input-B']], row[groups_dict[0]])\n",
    "    else:\n",
    "        # Unprivileged group: choose best between original and their LLM (Input-A)\n",
    "        return max(row[groups_dict[group]['Input-A']], row[groups_dict[0]])\n",
    "\n",
    "\n",
    "# Function 2: Map hirer scores (Two-ticket scheme)\n",
    "def map_hirer_score(row, group, groups_dict):\n",
    "    \"\"\"\n",
    "    Maps the score after the hirer applies their own LLM manipulation.\n",
    "    - If Will Manipulate = True: returns max(submitted, hirer_LLM_on_submitted) where submitted was already modified (Hirer-B)\n",
    "    - If Will Manipulate = False: returns max(submitted, hirer_LLM_on_submitted) where submitted was original (Hirer-A)\n",
    "    \"\"\"\n",
    "    if row['Will Manipulate']:\n",
    "        # Privileged: hirer applies LLM to already-modified resume (twice modified)\n",
    "        return max(row[groups_dict[group]['Input-B']], row[groups_dict[group]['Hirer-B']])\n",
    "    else:\n",
    "        # Unprivileged: hirer applies LLM to original resume (once modified by hirer)\n",
    "        return max(row[groups_dict[group]['Input-A']], row[groups_dict[group]['Hirer-A']])\n",
    "\n",
    "\n",
    "# Function 3: Calculate threshold with No False Positives objective\n",
    "def set_threshold_min_fpr(scores, labels, min_tpr=0.01):\n",
    "    \"\"\"\n",
    "    Find threshold that maximizes TPR while keeping FPR arbitrarily small (close to 0).\n",
    "    Returns only the threshold value.\n",
    "    \"\"\"\n",
    "    scores = np.array(scores)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    \n",
    "    # Find the index where TPR is just above min_tpr\n",
    "    valid_idx = np.where(tpr >= min_tpr)[0]\n",
    "    if len(valid_idx) > 0:\n",
    "        best_idx = valid_idx[0]\n",
    "        return thresholds[best_idx]\n",
    "    else:\n",
    "        # If no threshold gives TPR >= min_tpr, return the threshold with highest TPR\n",
    "        best_idx = np.argmax(tpr)\n",
    "        return thresholds[best_idx]\n",
    "\n",
    "\n",
    "# Function 4: Calculate disparity between groups\n",
    "def calculate_disparity(y_true, y_pred, y_manipulate_label):\n",
    "    \"\"\"\n",
    "    Calculate TPR disparity: TPR_privileged - TPR_unprivileged\n",
    "    \"\"\"\n",
    "    # Separate by manipulation group\n",
    "    y_true_privileged = [y_true[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == True]\n",
    "    y_pred_privileged = [y_pred[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == True]\n",
    "    \n",
    "    y_true_unprivileged = [y_true[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == False]\n",
    "    y_pred_unprivileged = [y_pred[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == False]\n",
    "    \n",
    "    # Calculate confusion matrices\n",
    "    tn_p, fp_p, fn_p, tp_p = confusion_matrix(y_true_privileged, y_pred_privileged).ravel()\n",
    "    tn_u, fp_u, fn_u, tp_u = confusion_matrix(y_true_unprivileged, y_pred_unprivileged).ravel()\n",
    "    \n",
    "    # Calculate TPRs\n",
    "    tpr_privileged = tp_p / (tp_p + fn_p) if (tp_p + fn_p) > 0 else 0\n",
    "    tpr_unprivileged = tp_u / (tp_u + fn_u) if (tp_u + fn_u) > 0 else 0\n",
    "    \n",
    "    return tpr_privileged - tpr_unprivileged\n",
    "\n",
    "\n",
    "# Function 5: Calculate TPR, FNR, and Accuracy\n",
    "def calculate_tpr_fnr_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate overall TPR, FNR, and Accuracy.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return tpr, fnr, accuracy\n",
    "\n",
    "\n",
    "print(\"Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Define Experimental Conditions\n",
    "\n",
    "We'll test three conditions from Table 1:\n",
    "1. **Condition 1**: Unprivileged (U) = No LLM, Privileged (P) = GPT-4o\n",
    "2. **Condition 2**: Unprivileged (U) = GPT-3.5, Privileged (P) = GPT-4o\n",
    "3. **Condition 3**: Unprivileged (U) = GPT-4o-mini, Privileged (P) = GPT-4o\n",
    "\n",
    "For each condition, we specify:\n",
    "- **Input-A**: Score the unprivileged group submits\n",
    "- **Input-B**: Score the privileged group submits\n",
    "- **Hirer-A**: Score after hirer applies LLM to unprivileged submission\n",
    "- **Hirer-B**: Score after hirer applies LLM to privileged submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental conditions defined:\n",
      "\n",
      "Condition 1:\n",
      "  Unprivileged Input: CV Google_UX Score\n",
      "  Privileged Input: GPT-4o Score\n",
      "  Hirer on Unprivileged: GPT-4o Score\n",
      "  Hirer on Privileged: GPT-4o on GPT-4o Score\n",
      "\n",
      "Condition 2:\n",
      "  Unprivileged Input: GPT-3.5 Score\n",
      "  Privileged Input: GPT-4o Score\n",
      "  Hirer on Unprivileged: GPT-4o on GPT-3.5 Score\n",
      "  Hirer on Privileged: GPT-4o on GPT-4o Score\n",
      "\n",
      "Condition 3:\n",
      "  Unprivileged Input: GPT-4o-mini Score\n",
      "  Privileged Input: GPT-4o Score\n",
      "  Hirer on Unprivileged: GPT-4o on GPT-4o-mini Score\n",
      "  Hirer on Privileged: GPT-4o on GPT-4o Score\n"
     ]
    }
   ],
   "source": [
    "groups_google_ux = {\n",
    "    0: 'CV Google_UX Score',  # Baseline original score\n",
    "    \n",
    "    # Condition 1: U: No LLM, P: GPT-4o\n",
    "    1: {\n",
    "        'Input-A': 'CV Google_UX Score',           # Unprivileged submits original\n",
    "        'Input-B': 'GPT-4o Score',                 # Privileged submits GPT-4o modified\n",
    "        'Hirer-A': 'GPT-4o Score',                 # Hirer applies GPT-4o to original\n",
    "        'Hirer-B': 'GPT-4o on GPT-4o Score'        # Hirer applies GPT-4o to GPT-4o modified\n",
    "    },\n",
    "    \n",
    "    # Condition 2: U: GPT-3.5, P: GPT-4o\n",
    "    2: {\n",
    "        'Input-A': 'GPT-3.5 Score',                # Unprivileged submits GPT-3.5 modified\n",
    "        'Input-B': 'GPT-4o Score',                 # Privileged submits GPT-4o modified\n",
    "        'Hirer-A': 'GPT-4o on GPT-3.5 Score',      # Hirer applies GPT-4o to GPT-3.5 modified\n",
    "        'Hirer-B': 'GPT-4o on GPT-4o Score'        # Hirer applies GPT-4o to GPT-4o modified\n",
    "    },\n",
    "    \n",
    "    # Condition 3: U: GPT-4o-mini, P: GPT-4o\n",
    "    3: {\n",
    "        'Input-A': 'GPT-4o-mini Score',            # Unprivileged submits GPT-4o-mini modified\n",
    "        'Input-B': 'GPT-4o Score',                 # Privileged submits GPT-4o modified\n",
    "        'Hirer-A': 'GPT-4o on GPT-4o-mini Score',  # Hirer applies GPT-4o to GPT-4o-mini modified\n",
    "        'Hirer-B': 'GPT-4o on GPT-4o Score'        # Hirer applies GPT-4o to GPT-4o modified\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Experimental conditions defined:\")\n",
    "for group_id in [1, 2, 3]:\n",
    "    print(f\"\\nCondition {group_id}:\")\n",
    "    print(f\"  Unprivileged Input: {groups_google_ux[group_id]['Input-A']}\")\n",
    "    print(f\"  Privileged Input: {groups_google_ux[group_id]['Input-B']}\")\n",
    "    print(f\"  Hirer on Unprivileged: {groups_google_ux[group_id]['Hirer-A']}\")\n",
    "    print(f\"  Hirer on Privileged: {groups_google_ux[group_id]['Hirer-B']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.5: Check and Clean Data\n",
    "\n",
    "Before running experiments, let's check for any NaN values and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values in the dataset...\n",
      "\n",
      "Total rows: 520\n",
      "\n",
      "NaN counts per column:\n",
      "Unnamed: 0                     0\n",
      "CV Google_UX Score             0\n",
      "UX True Label                  0\n",
      "GPT-3.5 Score                  0\n",
      "GPT-4o Score                   1\n",
      "GPT-4o-mini Score              1\n",
      "GPT-4o on GPT-3.5 Score        0\n",
      "GPT-4o on GPT-4o-mini Score    1\n",
      "GPT-4o on GPT-4o Score         0\n",
      "Will Manipulate                0\n",
      "dtype: int64\n",
      "\n",
      "Rows with at least one NaN: 1\n",
      "\n",
      "Removing rows with NaN values...\n",
      "Rows after cleaning: 519\n",
      "\n",
      "Label distribution after cleaning:\n",
      "UX True Label\n",
      "1    260\n",
      "0    259\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Will Manipulate distribution after cleaning:\n",
      "Will Manipulate\n",
      "False    260\n",
      "True     259\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(\"Checking for NaN values in the dataset...\")\n",
    "print(f\"\\nTotal rows: {len(df_combined)}\")\n",
    "print(f\"\\nNaN counts per column:\")\n",
    "print(df_combined.isnull().sum())\n",
    "\n",
    "# Check if any rows have NaN values\n",
    "rows_with_nan = df_combined.isnull().any(axis=1).sum()\n",
    "print(f\"\\nRows with at least one NaN: {rows_with_nan}\")\n",
    "\n",
    "if rows_with_nan > 0:\n",
    "    print(\"\\nRemoving rows with NaN values...\")\n",
    "    df_combined_clean = df_combined.dropna()\n",
    "    print(f\"Rows after cleaning: {len(df_combined_clean)}\")\n",
    "    print(f\"\\nLabel distribution after cleaning:\")\n",
    "    print(df_combined_clean['UX True Label'].value_counts())\n",
    "    print(f\"\\nWill Manipulate distribution after cleaning:\")\n",
    "    print(df_combined_clean['Will Manipulate'].value_counts())\n",
    "    \n",
    "    # Replace the original dataframe\n",
    "    df_combined = df_combined_clean\n",
    "else:\n",
    "    print(\"\\nNo NaN values found. Data is clean!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments...\n",
      "Total iterations per condition: 500\n",
      "Train-test split: 70/30\n",
      "\n",
      "\n",
      "============================================================\n",
      "Running Condition 1\n",
      "============================================================\n",
      "  Iteration 100/500\n",
      "  Iteration 200/500\n",
      "  Iteration 300/500\n",
      "  Iteration 400/500\n",
      "  Iteration 500/500\n",
      "\n",
      "============================================================\n",
      "Running Condition 2\n",
      "============================================================\n",
      "  Iteration 100/500\n",
      "  Iteration 200/500\n",
      "  Iteration 300/500\n",
      "  Iteration 400/500\n",
      "  Iteration 500/500\n",
      "\n",
      "============================================================\n",
      "Running Condition 3\n",
      "============================================================\n",
      "  Iteration 100/500\n",
      "  Iteration 200/500\n",
      "  Iteration 300/500\n",
      "  Iteration 400/500\n",
      "  Iteration 500/500\n",
      "\n",
      "============================================================\n",
      "Experiment completed!\n",
      "Total results: 3000 rows\n",
      "  - 3 conditions × 2 schemes × 500 iterations\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize results storage\n",
    "results = {\n",
    "    'Condition': [],\n",
    "    'Scheme': [],\n",
    "    'Iteration': [],\n",
    "    'TPR': [],\n",
    "    'TPR_Disparity': [],\n",
    "    'FNR': [],\n",
    "    'Accuracy': []\n",
    "}\n",
    "\n",
    "num_iterations = 500\n",
    "test_size = 0.3\n",
    "\n",
    "print(\"Running experiments...\")\n",
    "print(f\"Total iterations per condition: {num_iterations}\")\n",
    "print(f\"Train-test split: {int((1-test_size)*100)}/{int(test_size*100)}\\n\")\n",
    "\n",
    "# Run experiments for each condition\n",
    "for group_id in [1, 2, 3]:\n",
    "    condition_name = f\"Condition {group_id}\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running {condition_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        if (iteration + 1) % 100 == 0:\n",
    "            print(f\"  Iteration {iteration + 1}/{num_iterations}\")\n",
    "        \n",
    "        # Split data\n",
    "        train_df, test_df = train_test_split(\n",
    "            df_combined, \n",
    "            test_size=test_size, \n",
    "            random_state=42 + iteration,\n",
    "            stratify=df_combined['UX True Label']\n",
    "        )\n",
    "        \n",
    "        # Get true labels\n",
    "        y_train = train_df['UX True Label'].values\n",
    "        y_test = test_df['UX True Label'].values\n",
    "        y_test_manipulate = test_df['Will Manipulate'].values\n",
    "        \n",
    "        # === Traditional Scheme (1-ticket) ===\n",
    "        # Applicants submit best of original or their LLM-modified resume\n",
    "        train_df['Input Score'] = train_df.apply(\n",
    "            lambda row: map_input_score(row, group_id, groups_google_ux), axis=1\n",
    "        )\n",
    "        test_df['Input Score'] = test_df.apply(\n",
    "            lambda row: map_input_score(row, group_id, groups_google_ux), axis=1\n",
    "        )\n",
    "        \n",
    "        X_train_trad = train_df['Input Score'].values\n",
    "        X_test_trad = test_df['Input Score'].values\n",
    "        \n",
    "        # Find threshold on training set\n",
    "        threshold_trad = set_threshold_min_fpr(X_train_trad, y_train)\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        y_pred_trad = (X_test_trad >= threshold_trad).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tpr_trad, fnr_trad, acc_trad = calculate_tpr_fnr_accuracy(y_test, y_pred_trad)\n",
    "        disparity_trad = calculate_disparity(y_test, y_pred_trad, y_test_manipulate)\n",
    "        \n",
    "        # Store results\n",
    "        results['Condition'].append(condition_name)\n",
    "        results['Scheme'].append('Traditional')\n",
    "        results['Iteration'].append(iteration)\n",
    "        results['TPR'].append(tpr_trad)\n",
    "        results['TPR_Disparity'].append(disparity_trad)\n",
    "        results['FNR'].append(fnr_trad)\n",
    "        results['Accuracy'].append(acc_trad)\n",
    "        \n",
    "        # === Two-Ticket Scheme ===\n",
    "        # Hirer applies their LLM to submitted resumes\n",
    "        train_df['Hirer Score'] = train_df.apply(\n",
    "            lambda row: map_hirer_score(row, group_id, groups_google_ux), axis=1\n",
    "        )\n",
    "        test_df['Hirer Score'] = test_df.apply(\n",
    "            lambda row: map_hirer_score(row, group_id, groups_google_ux), axis=1\n",
    "        )\n",
    "        \n",
    "        X_train_two = train_df['Hirer Score'].values\n",
    "        X_test_two = test_df['Hirer Score'].values\n",
    "        \n",
    "        # Find threshold on training set\n",
    "        threshold_two = set_threshold_min_fpr(X_train_two, y_train)\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        y_pred_two = (X_test_two >= threshold_two).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tpr_two, fnr_two, acc_two = calculate_tpr_fnr_accuracy(y_test, y_pred_two)\n",
    "        disparity_two = calculate_disparity(y_test, y_pred_two, y_test_manipulate)\n",
    "        \n",
    "        # Store results\n",
    "        results['Condition'].append(condition_name)\n",
    "        results['Scheme'].append('Two-Ticket')\n",
    "        results['Iteration'].append(iteration)\n",
    "        results['TPR'].append(tpr_two)\n",
    "        results['TPR_Disparity'].append(disparity_two)\n",
    "        results['FNR'].append(fnr_two)\n",
    "        results['Accuracy'].append(acc_two)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Experiment completed!\")\n",
    "print(f\"Total results: {len(results_df)} rows\")\n",
    "print(f\"  - 3 conditions × 2 schemes × {num_iterations} iterations\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Table 1 Results\n",
    "\n",
    "Calculate mean TPR and TPR Disparity with 95% confidence intervals for each condition and scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLE 1 RESULTS: Google UX Designer Binary Classification\n",
      "================================================================================\n",
      "\n",
      "Role: Google UX Designer\n",
      "Qualified Resumes: 260 UX Designer resumes\n",
      "Unqualified Resumes: 260 Product Manager resumes\n",
      "Iterations: 500\n",
      "\n",
      "Objective: No False Positives (maximize TPR subject to FPR ≈ 0)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Condition 1: Traditional\n",
      "  TPR: 0.1347 (95% CI: [0.1213, 0.1481])\n",
      "  TPR Disparity: 0.1256 (95% CI: [0.1148, 0.1364])\n",
      "\n",
      "Condition 1: Two-Ticket\n",
      "  TPR: 0.1586 (95% CI: [0.1475, 0.1697])\n",
      "  TPR Disparity: -0.0389 (95% CI: [-0.0450, -0.0327])\n",
      "\n",
      "Condition 2: Traditional\n",
      "  TPR: 0.1416 (95% CI: [0.1283, 0.1549])\n",
      "  TPR Disparity: 0.0790 (95% CI: [0.0719, 0.0861])\n",
      "\n",
      "Condition 2: Two-Ticket\n",
      "  TPR: 0.1836 (95% CI: [0.1738, 0.1934])\n",
      "  TPR Disparity: 0.0280 (95% CI: [0.0210, 0.0350])\n",
      "\n",
      "Condition 3: Traditional\n",
      "  TPR: 0.0939 (95% CI: [0.0841, 0.1037])\n",
      "  TPR Disparity: -0.0214 (95% CI: [-0.0260, -0.0168])\n",
      "\n",
      "Condition 3: Two-Ticket\n",
      "  TPR: 0.1471 (95% CI: [0.1379, 0.1562])\n",
      "  TPR Disparity: -0.0335 (95% CI: [-0.0393, -0.0278])\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Formatted Table:\n",
      "  Condition      Scheme                     TPR              TPR Disparity\n",
      "Condition 1 Traditional 0.1347 [0.1213, 0.1481]    0.1256 [0.1148, 0.1364]\n",
      "Condition 1  Two-Ticket 0.1586 [0.1475, 0.1697] -0.0389 [-0.0450, -0.0327]\n",
      "Condition 2 Traditional 0.1416 [0.1283, 0.1549]    0.0790 [0.0719, 0.0861]\n",
      "Condition 2  Two-Ticket 0.1836 [0.1738, 0.1934]    0.0280 [0.0210, 0.0350]\n",
      "Condition 3 Traditional 0.0939 [0.0841, 0.1037] -0.0214 [-0.0260, -0.0168]\n",
      "Condition 3  Two-Ticket 0.1471 [0.1379, 0.1562] -0.0335 [-0.0393, -0.0278]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate statistics for each condition and scheme\n",
    "table1_results = []\n",
    "\n",
    "for condition in ['Condition 1', 'Condition 2', 'Condition 3']:\n",
    "    for scheme in ['Traditional', 'Two-Ticket']:\n",
    "        # Filter results for this condition and scheme\n",
    "        mask = (results_df['Condition'] == condition) & (results_df['Scheme'] == scheme)\n",
    "        subset = results_df[mask]\n",
    "        \n",
    "        # Calculate mean and 95% CI for TPR\n",
    "        tpr_values = subset['TPR'].values\n",
    "        tpr_mean = np.mean(tpr_values)\n",
    "        tpr_ci = stats.t.interval(0.95, len(tpr_values)-1, \n",
    "                                   loc=tpr_mean, \n",
    "                                   scale=stats.sem(tpr_values))\n",
    "        \n",
    "        # Calculate mean and 95% CI for TPR Disparity\n",
    "        disparity_values = subset['TPR_Disparity'].values\n",
    "        disparity_mean = np.mean(disparity_values)\n",
    "        disparity_ci = stats.t.interval(0.95, len(disparity_values)-1,\n",
    "                                        loc=disparity_mean,\n",
    "                                        scale=stats.sem(disparity_values))\n",
    "        \n",
    "        # Store results\n",
    "        table1_results.append({\n",
    "            'Condition': condition,\n",
    "            'Scheme': scheme,\n",
    "            'TPR_Mean': tpr_mean,\n",
    "            'TPR_CI_Lower': tpr_ci[0],\n",
    "            'TPR_CI_Upper': tpr_ci[1],\n",
    "            'TPR_Disparity_Mean': disparity_mean,\n",
    "            'TPR_Disparity_CI_Lower': disparity_ci[0],\n",
    "            'TPR_Disparity_CI_Upper': disparity_ci[1]\n",
    "        })\n",
    "\n",
    "# Create summary table\n",
    "table1_df = pd.DataFrame(table1_results)\n",
    "\n",
    "# Format for display\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE 1 RESULTS: Google UX Designer Binary Classification\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nRole: Google UX Designer\")\n",
    "print(f\"Qualified Resumes: 260 UX Designer resumes\")\n",
    "print(f\"Unqualified Resumes: 260 Product Manager resumes\")\n",
    "print(f\"Iterations: {num_iterations}\")\n",
    "print(f\"\\nObjective: No False Positives (maximize TPR subject to FPR ≈ 0)\")\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "\n",
    "for _, row in table1_df.iterrows():\n",
    "    print(f\"\\n{row['Condition']}: {row['Scheme']}\")\n",
    "    print(f\"  TPR: {row['TPR_Mean']:.4f} (95% CI: [{row['TPR_CI_Lower']:.4f}, {row['TPR_CI_Upper']:.4f}])\")\n",
    "    print(f\"  TPR Disparity: {row['TPR_Disparity_Mean']:.4f} (95% CI: [{row['TPR_Disparity_CI_Lower']:.4f}, {row['TPR_Disparity_CI_Upper']:.4f}])\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Display as formatted DataFrame\n",
    "print(\"\\n\\nFormatted Table:\")\n",
    "display_df = table1_df.copy()\n",
    "display_df['TPR'] = display_df.apply(\n",
    "    lambda row: f\"{row['TPR_Mean']:.4f} [{row['TPR_CI_Lower']:.4f}, {row['TPR_CI_Upper']:.4f}]\", \n",
    "    axis=1\n",
    ")\n",
    "display_df['TPR Disparity'] = display_df.apply(\n",
    "    lambda row: f\"{row['TPR_Disparity_Mean']:.4f} [{row['TPR_Disparity_CI_Lower']:.4f}, {row['TPR_Disparity_CI_Upper']:.4f}]\",\n",
    "    axis=1\n",
    ")\n",
    "print(display_df[['Condition', 'Scheme', 'TPR', 'TPR Disparity']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Detailed Statistics Table\n",
    "\n",
    "Generate comprehensive statistics comparing Traditional (1-ticket) vs Two-Ticket schemes, including:\n",
    "- Accuracy metrics\n",
    "- TPR and improvement\n",
    "- Disparity metrics\n",
    "- Threshold information\n",
    "- FNR (False Negative Rate)\n",
    "- Number of candidates accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Condition 1: DETAILED STATISTICS\n",
      "====================================================================================================\n",
      "\n",
      "Comparison of Traditional (1-ticket) vs Two-Ticket Schemes\n",
      "Based on 500 iterations\n",
      "\n",
      "       test_accuracy_1ticket  test_accuracy_2ticket  test_accuracy_improvement  test_tpr_1ticket  test_tpr_2ticket  tpr_improvement  test_disparity_1ticket  test_disparity_2_ticket  disparity_decrease_2_1  test_fnr_1ticket  test_fnr_2ticket\n",
      "count             500.000000             500.000000                 500.000000        500.000000        500.000000       500.000000              500.000000               500.000000              500.000000        500.000000        500.000000\n",
      "mean                0.567064               0.579192                   0.012128          0.134692          0.158564         0.023872                0.125611                -0.038877                0.164488          0.865308          0.841436\n",
      "std                 0.075285               0.062691                   0.056608          0.152274          0.126209         0.115222                0.123216                 0.069854                0.122880          0.152274          0.126209\n",
      "min                 0.500000               0.512821                  -0.256410          0.000000          0.025641        -0.576923               -0.061497                -0.227243               -0.046144          0.282051          0.205128\n",
      "25%                 0.519231               0.538462                   0.012821          0.038462          0.076923         0.025641                0.043651                -0.080592                0.077454          0.871795          0.820513\n",
      "50%                 0.532051               0.564103                   0.025641          0.064103          0.128205         0.051282                0.076923                -0.039895                0.130952          0.935897          0.871795\n",
      "75%                 0.564103               0.589744                   0.038462          0.128205          0.179487         0.076923                0.175368                 0.003459                0.225516          0.961538          0.923077\n",
      "max                 0.826923               0.891026                   0.230769          0.717949          0.794872         0.474359                0.512821                 0.223920                0.542105          1.000000          0.974359\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "KEY INSIGHTS FOR Condition 1:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TPR Improvement (mean): 0.0239 (17.7% increase)\n",
      "Accuracy Improvement (mean): 0.0121\n",
      "Disparity Decrease (mean): 0.1645\n",
      "  - Traditional disparity: 0.1256\n",
      "  - Two-Ticket disparity: -0.0389\n",
      "\n",
      "Two-Ticket wins:\n",
      "  - Higher TPR: 403/500 iterations (80.6%)\n",
      "  - Higher Accuracy: 403/500 iterations (80.6%)\n",
      "  - Lower Disparity: 488/500 iterations (97.6%)\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Condition 2: DETAILED STATISTICS\n",
      "====================================================================================================\n",
      "\n",
      "Comparison of Traditional (1-ticket) vs Two-Ticket Schemes\n",
      "Based on 500 iterations\n",
      "\n",
      "       test_accuracy_1ticket  test_accuracy_2ticket  test_accuracy_improvement  test_tpr_1ticket  test_tpr_2ticket  tpr_improvement  test_disparity_1ticket  test_disparity_2_ticket  disparity_decrease_2_1  test_fnr_1ticket  test_fnr_2ticket\n",
      "count             500.000000             500.000000                 500.000000        500.000000        500.000000       500.000000              500.000000               500.000000              500.000000        500.000000        500.000000\n",
      "mean                0.570692               0.591769                   0.021077          0.141615          0.183564         0.041949                0.078988                 0.027994                0.050995          0.858385          0.816436\n",
      "std                 0.075486               0.055681                   0.082305          0.151716          0.111472         0.165172                0.080525                 0.079669                0.081512          0.151716          0.111472\n",
      "min                 0.500000               0.519231                  -0.282051          0.000000          0.038462        -0.576923               -0.134219                -0.200000               -0.226263          0.333333          0.333333\n",
      "25%                 0.519231               0.557692                   0.006410          0.038462          0.115385         0.012821                0.025301                -0.026341                0.006661          0.846154          0.807692\n",
      "50%                 0.538462               0.570513                   0.025641          0.076923          0.141026         0.051282                0.053947                 0.020943                0.049123          0.923077          0.858974\n",
      "75%                 0.576923               0.596154                   0.051282          0.153846          0.192308         0.102564                0.109931                 0.079052                0.089561          0.961538          0.884615\n",
      "max                 0.826923               0.826923                   0.262821          0.666667          0.666667         0.525641                0.385382                 0.290640                0.440532          1.000000          0.961538\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "KEY INSIGHTS FOR Condition 2:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TPR Improvement (mean): 0.0419 (29.6% increase)\n",
      "Accuracy Improvement (mean): 0.0211\n",
      "Disparity Decrease (mean): 0.0510\n",
      "  - Traditional disparity: 0.0790\n",
      "  - Two-Ticket disparity: 0.0280\n",
      "\n",
      "Two-Ticket wins:\n",
      "  - Higher TPR: 390/500 iterations (78.0%)\n",
      "  - Higher Accuracy: 390/500 iterations (78.0%)\n",
      "  - Lower Disparity: 391/500 iterations (78.2%)\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Condition 3: DETAILED STATISTICS\n",
      "====================================================================================================\n",
      "\n",
      "Comparison of Traditional (1-ticket) vs Two-Ticket Schemes\n",
      "Based on 500 iterations\n",
      "\n",
      "       test_accuracy_1ticket  test_accuracy_2ticket  test_accuracy_improvement  test_tpr_1ticket  test_tpr_2ticket  tpr_improvement  test_disparity_1ticket  test_disparity_2_ticket  disparity_decrease_2_1  test_fnr_1ticket  test_fnr_2ticket\n",
      "count             500.000000             500.000000                 500.000000        500.000000        500.000000       500.000000              500.000000               500.000000              500.000000        500.000000        500.000000\n",
      "mean                0.546872               0.573449                   0.026577          0.093923          0.147077         0.053154               -0.021376                -0.033521                0.012145          0.906077          0.852923\n",
      "std                 0.055268               0.051741                   0.064259          0.111666          0.104171         0.129441                0.052645                 0.065588                0.054063          0.111666          0.104171\n",
      "min                 0.500000               0.506410                  -0.282051          0.000000          0.012821        -0.589744               -0.205128                -0.225000               -0.197980          0.115385          0.371795\n",
      "25%                 0.519231               0.544872                   0.006410          0.038462          0.089744         0.012821               -0.053947                -0.076923               -0.023256          0.910256          0.833333\n",
      "50%                 0.532051               0.557692                   0.019231          0.064103          0.115385         0.038462               -0.020553                -0.032097                0.007937          0.935897          0.884615\n",
      "75%                 0.544872               0.583333                   0.044872          0.089744          0.166667         0.089744                0.010379                 0.009358                0.047909          0.961538          0.910256\n",
      "max                 0.916667               0.814103                   0.307692          0.884615          0.628205         0.615385                0.163636                 0.228283                0.231229          1.000000          0.987179\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "KEY INSIGHTS FOR Condition 3:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TPR Improvement (mean): 0.0532 (56.6% increase)\n",
      "Accuracy Improvement (mean): 0.0266\n",
      "Disparity Decrease (mean): 0.0121\n",
      "  - Traditional disparity: -0.0214\n",
      "  - Two-Ticket disparity: -0.0335\n",
      "\n",
      "Two-Ticket wins:\n",
      "  - Higher TPR: 392/500 iterations (78.4%)\n",
      "  - Higher Accuracy: 392/500 iterations (78.4%)\n",
      "  - Lower Disparity: 273/500 iterations (54.6%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create detailed comparison DataFrames for each condition\n",
    "for group_id in [1, 2, 3]:\n",
    "    condition_name = f\"Condition {group_id}\"\n",
    "    \n",
    "    # Filter data for this condition\n",
    "    trad_mask = (results_df['Condition'] == condition_name) & (results_df['Scheme'] == 'Traditional')\n",
    "    two_mask = (results_df['Condition'] == condition_name) & (results_df['Scheme'] == 'Two-Ticket')\n",
    "    \n",
    "    trad_data = results_df[trad_mask].reset_index(drop=True)\n",
    "    two_data = results_df[two_mask].reset_index(drop=True)\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'test_accuracy_1ticket': trad_data['Accuracy'],\n",
    "        'test_accuracy_2ticket': two_data['Accuracy'],\n",
    "        'test_accuracy_improvement': two_data['Accuracy'] - trad_data['Accuracy'],\n",
    "        'test_tpr_1ticket': trad_data['TPR'],\n",
    "        'test_tpr_2ticket': two_data['TPR'],\n",
    "        'tpr_improvement': two_data['TPR'] - trad_data['TPR'],\n",
    "        'test_disparity_1ticket': trad_data['TPR_Disparity'],\n",
    "        'test_disparity_2_ticket': two_data['TPR_Disparity'],\n",
    "        'disparity_decrease_2_1': trad_data['TPR_Disparity'] - two_data['TPR_Disparity'],\n",
    "        'test_fnr_1ticket': trad_data['FNR'],\n",
    "        'test_fnr_2ticket': two_data['FNR']\n",
    "    })\n",
    "    \n",
    "    # Display statistics\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{condition_name}: DETAILED STATISTICS\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\nComparison of Traditional (1-ticket) vs Two-Ticket Schemes\")\n",
    "    print(f\"Based on {len(comparison_df)} iterations\\n\")\n",
    "    \n",
    "    # Display descriptive statistics\n",
    "    stats_df = comparison_df.describe()\n",
    "    print(stats_df.to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"\\nKEY INSIGHTS FOR {condition_name}:\")\n",
    "    print(\"-\"*100)\n",
    "    print(f\"TPR Improvement (mean): {comparison_df['tpr_improvement'].mean():.4f} \"\n",
    "          f\"({comparison_df['tpr_improvement'].mean()/comparison_df['test_tpr_1ticket'].mean()*100:.1f}% increase)\")\n",
    "    print(f\"Accuracy Improvement (mean): {comparison_df['test_accuracy_improvement'].mean():.4f}\")\n",
    "    print(f\"Disparity Decrease (mean): {comparison_df['disparity_decrease_2_1'].mean():.4f}\")\n",
    "    print(f\"  - Traditional disparity: {comparison_df['test_disparity_1ticket'].mean():.4f}\")\n",
    "    print(f\"  - Two-Ticket disparity: {comparison_df['test_disparity_2_ticket'].mean():.4f}\")\n",
    "    \n",
    "    # Check how often two-ticket is better\n",
    "    tpr_better = (comparison_df['tpr_improvement'] > 0).sum()\n",
    "    acc_better = (comparison_df['test_accuracy_improvement'] > 0).sum()\n",
    "    disp_better = (comparison_df['disparity_decrease_2_1'] > 0).sum()\n",
    "    \n",
    "    print(f\"\\nTwo-Ticket wins:\")\n",
    "    print(f\"  - Higher TPR: {tpr_better}/{len(comparison_df)} iterations ({tpr_better/len(comparison_df)*100:.1f}%)\")\n",
    "    print(f\"  - Higher Accuracy: {acc_better}/{len(comparison_df)} iterations ({acc_better/len(comparison_df)*100:.1f}%)\")\n",
    "    print(f\"  - Lower Disparity: {disp_better}/{len(comparison_df)} iterations ({disp_better/len(comparison_df)*100:.1f}%)\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
