{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DoorDash PM Binary Classification Analysis (Table 1 Reproduction - Extension Data)\n",
        "\n",
        "This notebook reproduces the binary classification results from Section 8 of the paper for the DoorDash PM role.\n",
        "\n",
        "**Extension data: 50 qualified + 50 unqualified resumes**\n",
        "\n",
        "We will test three conditions:\n",
        "1. **U: No LLMs, P: GPT-4O** - Unprivileged group has no LLM access, Privileged group uses GPT-4o\n",
        "2. **U: GPT-3.5, P: GPT-4O** - Unprivileged uses GPT-3.5, Privileged uses GPT-4o  \n",
        "3. **U: GPT-4O-MINI, P: GPT-4O** - Unprivileged uses GPT-4o-mini, Privileged uses GPT-4o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load and Merge Qualified and Unqualified Resume Scores\n",
        "\n",
        "- **Qualified**: PM resumes (n=50) - these ARE qualified for the PM role\n",
        "- **Unqualified**: UX designer resumes (n=50) - these are NOT qualified for the PM role"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized column names to: 'CV DoorDash PM Score'\n",
            "Qualified resumes: 50\n",
            "Unqualified resumes: 50\n",
            "\n",
            "Qualified sample:\n",
            "   Unnamed: 0  CV DoorDash PM Score  PM True Label\n",
            "0           0                81.061              1\n",
            "1           1                84.806              1\n",
            "2           2                81.328              1\n",
            "3           3                82.467              1\n",
            "4           4                81.239              1\n",
            "\n",
            "Unqualified sample:\n",
            "   Unnamed: 0  CV DoorDash PM Score  PM True Label\n",
            "0           0                78.009              0\n",
            "1           1                78.009              0\n",
            "2           2                77.359              0\n",
            "3           3                76.957              0\n",
            "4           4                78.456              0\n"
          ]
        }
      ],
      "source": [
        "# Load qualified resumes (PM resumes)\n",
        "qualified_original = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_Original_File_PM.csv')\n",
        "qualified_original['PM True Label'] = 1  # Qualified for PM role\n",
        "\n",
        "# Load unqualified resumes (UX resumes)\n",
        "unqualified_original = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoorDash_PM_Original_File_UX.csv')\n",
        "unqualified_original['PM True Label'] = 0  # Unqualified for PM role\n",
        "\n",
        "# IMPORTANT: Standardize column names - they differ between files\n",
        "qualified_cols = [col for col in qualified_original.columns if 'DoorDash' in col or 'Doordash' in col]\n",
        "unqualified_cols = [col for col in unqualified_original.columns if 'DoorDash' in col or 'Doordash' in col]\n",
        "\n",
        "if qualified_cols and unqualified_cols:\n",
        "    qualified_original.rename(columns={qualified_cols[0]: 'CV DoorDash PM Score'}, inplace=True)\n",
        "    unqualified_original.rename(columns={unqualified_cols[0]: 'CV DoorDash PM Score'}, inplace=True)\n",
        "    print(f\"Standardized column names to: 'CV DoorDash PM Score'\")\n",
        "\n",
        "# FIX: Keep only first 50 qualified resumes to get exactly 100 total\n",
        "qualified_original = qualified_original.head(50)\n",
        "\n",
        "print(f\"Qualified resumes: {len(qualified_original)}\")\n",
        "print(f\"Unqualified resumes: {len(unqualified_original)}\")\n",
        "print(\"\\nQualified sample:\")\n",
        "print(qualified_original.head())\n",
        "print(\"\\nUnqualified sample:\")\n",
        "print(unqualified_original.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load All Modified Resume Scores\n",
        "\n",
        "We need to load scores for:\n",
        "- GPT-3.5 modified\n",
        "- GPT-4o modified (once)\n",
        "- GPT-4o-mini modified\n",
        "- GPT-4o on GPT-3.5 (twice modified)\n",
        "- GPT-4o on GPT-4o-mini (twice modified)\n",
        "- GPT-4o on GPT-4o (twice modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All score files loaded successfully!\n",
            "Each file has 50 qualified and 50 unqualified resumes\n"
          ]
        }
      ],
      "source": [
        "# Load GPT-3.5 modified scores\n",
        "qualified_gpt35 = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt35turbo.csv').head(50)\n",
        "unqualified_gpt35 = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt35turbo.csv')\n",
        "\n",
        "# Load GPT-4o modified scores (once)\n",
        "qualified_gpt4o = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoorDash_PM_gpt4o.csv').head(50)\n",
        "unqualified_gpt4o = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4o.csv')\n",
        "\n",
        "# Load GPT-4o-mini modified scores\n",
        "qualified_gpt4omini = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt4omini.csv').head(50)\n",
        "unqualified_gpt4omini = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4omini.csv')\n",
        "\n",
        "# Load GPT-4o on GPT-3.5 scores\n",
        "qualified_gpt4o_on_gpt35 = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt4o_on_gpt35turbo.csv').head(50)\n",
        "unqualified_gpt4o_on_gpt35 = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4o_on_gpt35turbo.csv')\n",
        "\n",
        "# Load GPT-4o on GPT-4o-mini scores\n",
        "qualified_gpt4o_on_gpt4omini = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt4o_on_gpt4omini.csv').head(50)\n",
        "unqualified_gpt4o_on_gpt4omini = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4o_on_gpt4omini.csv')\n",
        "\n",
        "# Load GPT-4o on GPT-4o scores (twice modified)\n",
        "qualified_gpt4o_on_gpt4o = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt4o_on_gpt4o.csv').head(50)\n",
        "unqualified_gpt4o_on_gpt4o = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4o_on_gpt4o.csv')\n",
        "\n",
        "print(\"All score files loaded successfully!\")\n",
        "print(f\"Each file has {len(qualified_gpt35)} qualified and {len(unqualified_gpt35)} unqualified resumes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Merge All Scores into Single Dataframe\n",
        "\n",
        "We'll create one dataframe with all score columns for easier manipulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined dataframe shape: (100, 9)\n",
            "Total resumes: 100\n",
            "\n",
            "Columns: ['Unnamed: 0', 'CV DoorDash PM Score', 'PM True Label', 'GPT-3.5 Score', 'GPT-4o Score', 'GPT-4o-mini Score', 'GPT-4o on GPT-3.5 Score', 'GPT-4o on GPT-4o-mini Score', 'GPT-4o on GPT-4o Score']\n",
            "\n",
            "Label distribution:\n",
            "PM True Label\n",
            "1    50\n",
            "0    50\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Merge qualified scores\n",
        "qualified_df = qualified_original.copy()\n",
        "qualified_df['GPT-3.5 Score'] = qualified_gpt35.iloc[:, 1].values\n",
        "qualified_df['GPT-4o Score'] = qualified_gpt4o.iloc[:, 1].values\n",
        "qualified_df['GPT-4o-mini Score'] = qualified_gpt4omini.iloc[:, 1].values\n",
        "qualified_df['GPT-4o on GPT-3.5 Score'] = qualified_gpt4o_on_gpt35.iloc[:, 1].values\n",
        "qualified_df['GPT-4o on GPT-4o-mini Score'] = qualified_gpt4o_on_gpt4omini.iloc[:, 1].values\n",
        "qualified_df['GPT-4o on GPT-4o Score'] = qualified_gpt4o_on_gpt4o.iloc[:, 1].values\n",
        "\n",
        "# Merge unqualified scores\n",
        "unqualified_df = unqualified_original.copy()\n",
        "unqualified_df['GPT-3.5 Score'] = unqualified_gpt35.iloc[:, 1].values\n",
        "unqualified_df['GPT-4o Score'] = unqualified_gpt4o.iloc[:, 1].values\n",
        "unqualified_df['GPT-4o-mini Score'] = unqualified_gpt4omini.iloc[:, 1].values\n",
        "unqualified_df['GPT-4o on GPT-3.5 Score'] = unqualified_gpt4o_on_gpt35.iloc[:, 1].values\n",
        "unqualified_df['GPT-4o on GPT-4o-mini Score'] = unqualified_gpt4o_on_gpt4omini.iloc[:, 1].values\n",
        "unqualified_df['GPT-4o on GPT-4o Score'] = unqualified_gpt4o_on_gpt4o.iloc[:, 1].values\n",
        "\n",
        "# Combine qualified and unqualified\n",
        "df_combined = pd.concat([qualified_df, unqualified_df], ignore_index=True)\n",
        "\n",
        "print(f\"Combined dataframe shape: {df_combined.shape}\")\n",
        "print(f\"Total resumes: {len(df_combined)}\")\n",
        "print(f\"\\nColumns: {df_combined.columns.tolist()}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(df_combined['PM True Label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Randomly Assign \"Will Manipulate\" Groups\n",
        "\n",
        "Randomly assign 50 resumes to Privileged group (P, Will Manipulate=True) and 50 to Unprivileged group (U, Will Manipulate=False).\n",
        "\n",
        "This assignment is independent of whether the resume is qualified or unqualified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Will Manipulate distribution:\n",
            "Will Manipulate\n",
            "True     50\n",
            "False    50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Cross-tabulation of True Label vs Will Manipulate:\n",
            "Will Manipulate  False  True \n",
            "PM True Label                \n",
            "0                   30     20\n",
            "1                   20     30\n",
            "\n",
            "Sample of data with new column:\n",
            "   CV DoorDash PM Score  PM True Label  Will Manipulate\n",
            "0                81.061              1             True\n",
            "1                84.806              1            False\n",
            "2                81.328              1            False\n",
            "3                82.467              1            False\n",
            "4                81.239              1             True\n",
            "5                78.576              1             True\n",
            "6                81.196              1            False\n",
            "7                80.252              1             True\n",
            "8                84.576              1            False\n",
            "9                79.446              1             True\n"
          ]
        }
      ],
      "source": [
        "# Randomly assign Will Manipulate groups (50/50 split)\n",
        "np.random.seed(42)\n",
        "indices = np.arange(len(df_combined))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# First 50 get Will Manipulate = True, next 50 get False\n",
        "df_combined['Will Manipulate'] = False\n",
        "df_combined.loc[indices[:50], 'Will Manipulate'] = True\n",
        "\n",
        "# Verify the assignment\n",
        "print(\"Will Manipulate distribution:\")\n",
        "print(df_combined['Will Manipulate'].value_counts())\n",
        "print(\"\\nCross-tabulation of True Label vs Will Manipulate:\")\n",
        "print(pd.crosstab(df_combined['PM True Label'], df_combined['Will Manipulate']))\n",
        "print(\"\\nSample of data with new column:\")\n",
        "print(df_combined[['CV DoorDash PM Score', 'PM True Label', 'Will Manipulate']].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Define Helper Functions\n",
        "\n",
        "These functions replicate the methodology from the paper:\n",
        "1. **Score mapping functions**: Map original and modified scores based on group assignment\n",
        "2. **Threshold calculation**: Find optimal threshold with No False Positives objective\n",
        "3. **Metrics calculation**: Calculate TPR, FNR, Accuracy, and Disparity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# Function 1: Map input scores (Traditional 1-ticket scheme)\n",
        "def map_input_score(row, group, groups_dict):\n",
        "    \"\"\"\n",
        "    Maps the score that the applicant submits to the hiring system.\n",
        "    - If Will Manipulate = True (Privileged): returns max(original, privileged_LLM_score)\n",
        "    - If Will Manipulate = False (Unprivileged): returns max(original, unprivileged_LLM_score)\n",
        "    \"\"\"\n",
        "    if row['Will Manipulate']:\n",
        "        # Privileged group: choose best between original and their LLM (Input-B)\n",
        "        return max(row[groups_dict[group]['Input-B']], row[groups_dict[0]])\n",
        "    else:\n",
        "        # Unprivileged group: choose best between original and their LLM (Input-A)\n",
        "        return max(row[groups_dict[group]['Input-A']], row[groups_dict[0]])\n",
        "\n",
        "\n",
        "# Function 2: Map hirer scores (Two-ticket scheme)\n",
        "def map_hirer_score(row, group, groups_dict):\n",
        "    \"\"\"\n",
        "    Maps the score after the hirer applies their own LLM manipulation.\n",
        "    - If Will Manipulate = True: returns max(submitted, hirer_LLM_on_submitted) where submitted was already modified (Hirer-B)\n",
        "    - If Will Manipulate = False: returns max(submitted, hirer_LLM_on_submitted) where submitted was original (Hirer-A)\n",
        "    \"\"\"\n",
        "    if row['Will Manipulate']:\n",
        "        # Privileged: hirer applies LLM to already-modified resume (twice modified)\n",
        "        return max(row[groups_dict[group]['Input-B']], row[groups_dict[group]['Hirer-B']])\n",
        "    else:\n",
        "        # Unprivileged: hirer applies LLM to original resume (once modified by hirer)\n",
        "        return max(row[groups_dict[group]['Input-A']], row[groups_dict[group]['Hirer-A']])\n",
        "\n",
        "\n",
        "# Function 3: Calculate threshold with No False Positives objective\n",
        "def set_threshold_min_fpr(scores, labels, min_tpr=0.01):\n",
        "    \"\"\"\n",
        "    Find threshold that maximizes TPR while keeping FPR arbitrarily small (close to 0).\n",
        "    Returns only the threshold value.\n",
        "    \"\"\"\n",
        "    scores = np.array(scores)\n",
        "    labels = np.array(labels)\n",
        "    \n",
        "    # Calculate ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
        "    \n",
        "    # Find the index where TPR is just above min_tpr\n",
        "    valid_idx = np.where(tpr >= min_tpr)[0]\n",
        "    if len(valid_idx) > 0:\n",
        "        best_idx = valid_idx[0]\n",
        "        return thresholds[best_idx]\n",
        "    else:\n",
        "        # If no threshold gives TPR >= min_tpr, return the threshold with highest TPR\n",
        "        best_idx = np.argmax(tpr)\n",
        "        return thresholds[best_idx]\n",
        "\n",
        "\n",
        "# Function 4: Calculate disparity between groups\n",
        "def calculate_disparity(y_true, y_pred, y_manipulate_label):\n",
        "    \"\"\"\n",
        "    Calculate TPR disparity: TPR_privileged - TPR_unprivileged\n",
        "    \"\"\"\n",
        "    # Separate by manipulation group\n",
        "    y_true_privileged = [y_true[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == True]\n",
        "    y_pred_privileged = [y_pred[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == True]\n",
        "    \n",
        "    y_true_unprivileged = [y_true[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == False]\n",
        "    y_pred_unprivileged = [y_pred[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == False]\n",
        "    \n",
        "    # Calculate confusion matrices\n",
        "    tn_p, fp_p, fn_p, tp_p = confusion_matrix(y_true_privileged, y_pred_privileged).ravel()\n",
        "    tn_u, fp_u, fn_u, tp_u = confusion_matrix(y_true_unprivileged, y_pred_unprivileged).ravel()\n",
        "    \n",
        "    # Calculate TPRs\n",
        "    tpr_privileged = tp_p / (tp_p + fn_p) if (tp_p + fn_p) > 0 else 0\n",
        "    tpr_unprivileged = tp_u / (tp_u + fn_u) if (tp_u + fn_u) > 0 else 0\n",
        "    \n",
        "    return tpr_privileged - tpr_unprivileged\n",
        "\n",
        "\n",
        "# Function 5: Calculate TPR, FNR, and Accuracy\n",
        "def calculate_tpr_fnr_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate overall TPR, FNR, and Accuracy.\n",
        "    \"\"\"\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "    return tpr, fnr, accuracy\n",
        "\n",
        "\n",
        "print(\"Helper functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Define Experimental Conditions\n",
        "\n",
        "We'll test three conditions from Table 1:\n",
        "1. **Condition 1**: Unprivileged (U) = No LLM, Privileged (P) = GPT-4o\n",
        "2. **Condition 2**: Unprivileged (U) = GPT-3.5, Privileged (P) = GPT-4o\n",
        "3. **Condition 3**: Unprivileged (U) = GPT-4o-mini, Privileged (P) = GPT-4o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experimental conditions defined:\n",
            "\n",
            "Condition 1:\n",
            "  Unprivileged Input: CV DoorDash PM Score\n",
            "  Privileged Input: GPT-4o Score\n",
            "  Hirer on Unprivileged: GPT-4o Score\n",
            "  Hirer on Privileged: GPT-4o on GPT-4o Score\n",
            "\n",
            "Condition 2:\n",
            "  Unprivileged Input: GPT-3.5 Score\n",
            "  Privileged Input: GPT-4o Score\n",
            "  Hirer on Unprivileged: GPT-4o on GPT-3.5 Score\n",
            "  Hirer on Privileged: GPT-4o on GPT-4o Score\n",
            "\n",
            "Condition 3:\n",
            "  Unprivileged Input: GPT-4o-mini Score\n",
            "  Privileged Input: GPT-4o Score\n",
            "  Hirer on Unprivileged: GPT-4o on GPT-4o-mini Score\n",
            "  Hirer on Privileged: GPT-4o on GPT-4o Score\n"
          ]
        }
      ],
      "source": [
        "groups_doordash_pm = {\n",
        "    0: 'CV DoorDash PM Score',  # Baseline original score\n",
        "    \n",
        "    # Condition 1: U: No LLM, P: GPT-4o\n",
        "    1: {\n",
        "        'Input-A': 'CV DoorDash PM Score',           # Unprivileged submits original\n",
        "        'Input-B': 'GPT-4o Score',                 # Privileged submits GPT-4o modified\n",
        "        'Hirer-A': 'GPT-4o Score',                 # Hirer applies GPT-4o to original\n",
        "        'Hirer-B': 'GPT-4o on GPT-4o Score'        # Hirer applies GPT-4o to GPT-4o modified\n",
        "    },\n",
        "    \n",
        "    # Condition 2: U: GPT-3.5, P: GPT-4o\n",
        "    2: {\n",
        "        'Input-A': 'GPT-3.5 Score',                # Unprivileged submits GPT-3.5 modified\n",
        "        'Input-B': 'GPT-4o Score',                 # Privileged submits GPT-4o modified\n",
        "        'Hirer-A': 'GPT-4o on GPT-3.5 Score',      # Hirer applies GPT-4o to GPT-3.5 modified\n",
        "        'Hirer-B': 'GPT-4o on GPT-4o Score'        # Hirer applies GPT-4o to GPT-4o modified\n",
        "    },\n",
        "    \n",
        "    # Condition 3: U: GPT-4o-mini, P: GPT-4o\n",
        "    3: {\n",
        "        'Input-A': 'GPT-4o-mini Score',            # Unprivileged submits GPT-4o-mini modified\n",
        "        'Input-B': 'GPT-4o Score',                 # Privileged submits GPT-4o modified\n",
        "        'Hirer-A': 'GPT-4o on GPT-4o-mini Score',  # Hirer applies GPT-4o to GPT-4o-mini modified\n",
        "        'Hirer-B': 'GPT-4o on GPT-4o Score'        # Hirer applies GPT-4o to GPT-4o modified\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Experimental conditions defined:\")\n",
        "for group_id in [1, 2, 3]:\n",
        "    print(f\"\\nCondition {group_id}:\")\n",
        "    print(f\"  Unprivileged Input: {groups_doordash_pm[group_id]['Input-A']}\")\n",
        "    print(f\"  Privileged Input: {groups_doordash_pm[group_id]['Input-B']}\")\n",
        "    print(f\"  Hirer on Unprivileged: {groups_doordash_pm[group_id]['Hirer-A']}\")\n",
        "    print(f\"  Hirer on Privileged: {groups_doordash_pm[group_id]['Hirer-B']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Run 500-Iteration Experiment\n",
        "\n",
        "For each condition, we'll:\n",
        "1. Run 500 iterations with random 70/30 train-test splits\n",
        "2. Test both Traditional (1-ticket) and Two-ticket hiring schemes\n",
        "3. Calculate TPR, TPR Disparity, FNR, and Accuracy for each iteration\n",
        "4. Store results for statistical analysis\n",
        "\n",
        "**Note**: With 100 total resumes, test set will be ~30 resumes per iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running experiments...\n",
            "Total iterations per condition: 500\n",
            "Train-test split: 70/30\n",
            "\n",
            "\n",
            "============================================================\n",
            "Running Condition 1\n",
            "============================================================\n",
            "  Iteration 100/500\n",
            "  Iteration 200/500\n",
            "  Iteration 300/500\n",
            "  Iteration 400/500\n",
            "  Iteration 500/500\n",
            "\n",
            "============================================================\n",
            "Running Condition 2\n",
            "============================================================\n",
            "  Iteration 100/500\n",
            "  Iteration 200/500\n",
            "  Iteration 300/500\n",
            "  Iteration 400/500\n",
            "  Iteration 500/500\n",
            "\n",
            "============================================================\n",
            "Running Condition 3\n",
            "============================================================\n",
            "  Iteration 100/500\n",
            "  Iteration 200/500\n",
            "  Iteration 300/500\n",
            "  Iteration 400/500\n",
            "  Iteration 500/500\n",
            "\n",
            "============================================================\n",
            "Experiment completed!\n",
            "Total results: 3000 rows\n",
            "  - 3 conditions × 2 schemes × 500 iterations\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Initialize results storage\n",
        "results = {\n",
        "    'Condition': [],\n",
        "    'Scheme': [],\n",
        "    'Iteration': [],\n",
        "    'TPR': [],\n",
        "    'TPR_Disparity': [],\n",
        "    'FNR': [],\n",
        "    'Accuracy': []\n",
        "}\n",
        "\n",
        "num_iterations = 500\n",
        "test_size = 0.3\n",
        "\n",
        "print(\"Running experiments...\")\n",
        "print(f\"Total iterations per condition: {num_iterations}\")\n",
        "print(f\"Train-test split: {int((1-test_size)*100)}/{int(test_size*100)}\\n\")\n",
        "\n",
        "# Run experiments for each condition\n",
        "for group_id in [1, 2, 3]:\n",
        "    condition_name = f\"Condition {group_id}\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running {condition_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    for iteration in range(num_iterations):\n",
        "        if (iteration + 1) % 100 == 0:\n",
        "            print(f\"  Iteration {iteration + 1}/{num_iterations}\")\n",
        "        \n",
        "        # Split data\n",
        "        train_df, test_df = train_test_split(\n",
        "            df_combined, \n",
        "            test_size=test_size, \n",
        "            random_state=42 + iteration,\n",
        "            stratify=df_combined['PM True Label']\n",
        "        )\n",
        "        \n",
        "        # Get true labels\n",
        "        y_train = train_df['PM True Label'].values\n",
        "        y_test = test_df['PM True Label'].values\n",
        "        y_test_manipulate = test_df['Will Manipulate'].values\n",
        "        \n",
        "        # === Traditional Scheme (1-ticket) ===\n",
        "        train_df['Input Score'] = train_df.apply(\n",
        "            lambda row: map_input_score(row, group_id, groups_doordash_pm), axis=1\n",
        "        )\n",
        "        test_df['Input Score'] = test_df.apply(\n",
        "            lambda row: map_input_score(row, group_id, groups_doordash_pm), axis=1\n",
        "        )\n",
        "        \n",
        "        X_train_trad = train_df['Input Score'].values\n",
        "        X_test_trad = test_df['Input Score'].values\n",
        "        \n",
        "        # Find threshold and make predictions\n",
        "        threshold_trad = set_threshold_min_fpr(X_train_trad, y_train)\n",
        "        y_pred_trad = (X_test_trad >= threshold_trad).astype(int)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        tpr_trad, fnr_trad, acc_trad = calculate_tpr_fnr_accuracy(y_test, y_pred_trad)\n",
        "        disparity_trad = calculate_disparity(y_test, y_pred_trad, y_test_manipulate)\n",
        "        \n",
        "        # Store results\n",
        "        results['Condition'].append(condition_name)\n",
        "        results['Scheme'].append('Traditional')\n",
        "        results['Iteration'].append(iteration)\n",
        "        results['TPR'].append(tpr_trad)\n",
        "        results['TPR_Disparity'].append(disparity_trad)\n",
        "        results['FNR'].append(fnr_trad)\n",
        "        results['Accuracy'].append(acc_trad)\n",
        "        \n",
        "        # === Two-Ticket Scheme ===\n",
        "        train_df['Hirer Score'] = train_df.apply(\n",
        "            lambda row: map_hirer_score(row, group_id, groups_doordash_pm), axis=1\n",
        "        )\n",
        "        test_df['Hirer Score'] = test_df.apply(\n",
        "            lambda row: map_hirer_score(row, group_id, groups_doordash_pm), axis=1\n",
        "        )\n",
        "        \n",
        "        X_train_two = train_df['Hirer Score'].values\n",
        "        X_test_two = test_df['Hirer Score'].values\n",
        "        \n",
        "        # Find threshold and make predictions\n",
        "        threshold_two = set_threshold_min_fpr(X_train_two, y_train)\n",
        "        y_pred_two = (X_test_two >= threshold_two).astype(int)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        tpr_two, fnr_two, acc_two = calculate_tpr_fnr_accuracy(y_test, y_pred_two)\n",
        "        disparity_two = calculate_disparity(y_test, y_pred_two, y_test_manipulate)\n",
        "        \n",
        "        # Store results\n",
        "        results['Condition'].append(condition_name)\n",
        "        results['Scheme'].append('Two-Ticket')\n",
        "        results['Iteration'].append(iteration)\n",
        "        results['TPR'].append(tpr_two)\n",
        "        results['TPR_Disparity'].append(disparity_two)\n",
        "        results['FNR'].append(fnr_two)\n",
        "        results['Accuracy'].append(acc_two)\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Experiment completed!\")\n",
        "print(f\"Total results: {len(results_df)} rows\")\n",
        "print(f\"  - 3 conditions × 2 schemes × {num_iterations} iterations\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Generate Table 1 Results\n",
        "\n",
        "Calculate mean TPR and TPR Disparity with 95% confidence intervals for each condition and scheme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TABLE 1 RESULTS: DoorDash PM Binary Classification (Extension Data)\n",
            "================================================================================\n",
            "\n",
            "Role: DoorDash PM\n",
            "Qualified Resumes: 50 PM resumes\n",
            "Unqualified Resumes: 50 UX Designer resumes\n",
            "Iterations: 500\n",
            "\n",
            "Objective: No False Positives (maximize TPR subject to FPR ≈ 0)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Condition 1: Traditional\n",
            "  TPR: 0.0284 (95% CI: [0.0241, 0.0327])\n",
            "  TPR Disparity: 0.0467 (95% CI: [0.0398, 0.0537])\n",
            "\n",
            "Condition 1: Two-Ticket\n",
            "  TPR: 0.0252 (95% CI: [0.0211, 0.0293])\n",
            "  TPR Disparity: -0.0592 (95% CI: [-0.0687, -0.0497])\n",
            "\n",
            "Condition 2: Traditional\n",
            "  TPR: 0.0284 (95% CI: [0.0241, 0.0327])\n",
            "  TPR Disparity: 0.0467 (95% CI: [0.0398, 0.0537])\n",
            "\n",
            "Condition 2: Two-Ticket\n",
            "  TPR: 0.0284 (95% CI: [0.0241, 0.0327])\n",
            "  TPR Disparity: 0.0469 (95% CI: [0.0398, 0.0540])\n",
            "\n",
            "Condition 3: Traditional\n",
            "  TPR: 0.0284 (95% CI: [0.0241, 0.0327])\n",
            "  TPR Disparity: 0.0467 (95% CI: [0.0398, 0.0537])\n",
            "\n",
            "Condition 3: Two-Ticket\n",
            "  TPR: 0.0284 (95% CI: [0.0241, 0.0327])\n",
            "  TPR Disparity: 0.0469 (95% CI: [0.0398, 0.0540])\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Formatted Table:\n",
            "  Condition      Scheme                     TPR              TPR Disparity\n",
            "Condition 1 Traditional 0.0284 [0.0241, 0.0327]    0.0467 [0.0398, 0.0537]\n",
            "Condition 1  Two-Ticket 0.0252 [0.0211, 0.0293] -0.0592 [-0.0687, -0.0497]\n",
            "Condition 2 Traditional 0.0284 [0.0241, 0.0327]    0.0467 [0.0398, 0.0537]\n",
            "Condition 2  Two-Ticket 0.0284 [0.0241, 0.0327]    0.0469 [0.0398, 0.0540]\n",
            "Condition 3 Traditional 0.0284 [0.0241, 0.0327]    0.0467 [0.0398, 0.0537]\n",
            "Condition 3  Two-Ticket 0.0284 [0.0241, 0.0327]    0.0469 [0.0398, 0.0540]\n"
          ]
        }
      ],
      "source": [
        "# Calculate statistics for each condition and scheme\n",
        "table1_results = []\n",
        "\n",
        "for condition in ['Condition 1', 'Condition 2', 'Condition 3']:\n",
        "    for scheme in ['Traditional', 'Two-Ticket']:\n",
        "        # Filter results for this condition and scheme\n",
        "        mask = (results_df['Condition'] == condition) & (results_df['Scheme'] == scheme)\n",
        "        subset = results_df[mask]\n",
        "        \n",
        "        # Calculate mean and 95% CI for TPR\n",
        "        tpr_values = subset['TPR'].values\n",
        "        tpr_mean = np.mean(tpr_values)\n",
        "        tpr_ci = stats.t.interval(0.95, len(tpr_values)-1, \n",
        "                                   loc=tpr_mean, \n",
        "                                   scale=stats.sem(tpr_values))\n",
        "        \n",
        "        # Calculate mean and 95% CI for TPR Disparity\n",
        "        disparity_values = subset['TPR_Disparity'].values\n",
        "        disparity_mean = np.mean(disparity_values)\n",
        "        disparity_ci = stats.t.interval(0.95, len(disparity_values)-1,\n",
        "                                        loc=disparity_mean,\n",
        "                                        scale=stats.sem(disparity_values))\n",
        "        \n",
        "        # Store results\n",
        "        table1_results.append({\n",
        "            'Condition': condition,\n",
        "            'Scheme': scheme,\n",
        "            'TPR_Mean': tpr_mean,\n",
        "            'TPR_CI_Lower': tpr_ci[0],\n",
        "            'TPR_CI_Upper': tpr_ci[1],\n",
        "            'TPR_Disparity_Mean': disparity_mean,\n",
        "            'TPR_Disparity_CI_Lower': disparity_ci[0],\n",
        "            'TPR_Disparity_CI_Upper': disparity_ci[1]\n",
        "        })\n",
        "\n",
        "# Create summary table\n",
        "table1_df = pd.DataFrame(table1_results)\n",
        "\n",
        "# Format for display\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TABLE 1 RESULTS: DoorDash PM Binary Classification (Extension Data)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nRole: DoorDash PM\")\n",
        "print(f\"Qualified Resumes: 50 PM resumes\")\n",
        "print(f\"Unqualified Resumes: 50 UX Designer resumes\")\n",
        "print(f\"Iterations: {num_iterations}\")\n",
        "print(f\"\\nObjective: No False Positives (maximize TPR subject to FPR ≈ 0)\")\n",
        "print(\"\\n\" + \"-\"*80)\n",
        "\n",
        "for _, row in table1_df.iterrows():\n",
        "    print(f\"\\n{row['Condition']}: {row['Scheme']}\")\n",
        "    print(f\"  TPR: {row['TPR_Mean']:.4f} (95% CI: [{row['TPR_CI_Lower']:.4f}, {row['TPR_CI_Upper']:.4f}])\")\n",
        "    print(f\"  TPR Disparity: {row['TPR_Disparity_Mean']:.4f} (95% CI: [{row['TPR_Disparity_CI_Lower']:.4f}, {row['TPR_Disparity_CI_Upper']:.4f}])\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# Display as formatted DataFrame\n",
        "print(\"\\n\\nFormatted Table:\")\n",
        "display_df = table1_df.copy()\n",
        "display_df['TPR'] = display_df.apply(\n",
        "    lambda row: f\"{row['TPR_Mean']:.4f} [{row['TPR_CI_Lower']:.4f}, {row['TPR_CI_Upper']:.4f}]\", \n",
        "    axis=1\n",
        ")\n",
        "display_df['TPR Disparity'] = display_df.apply(\n",
        "    lambda row: f\"{row['TPR_Disparity_Mean']:.4f} [{row['TPR_Disparity_CI_Lower']:.4f}, {row['TPR_Disparity_CI_Upper']:.4f}]\",\n",
        "    axis=1\n",
        ")\n",
        "print(display_df[['Condition', 'Scheme', 'TPR', 'TPR Disparity']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Detailed Statistics Table\n",
        "\n",
        "Generate comprehensive statistics comparing Traditional (1-ticket) vs Two-Ticket schemes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Condition 1: DETAILED STATISTICS\n",
            "====================================================================================================\n",
            "\n",
            "Comparison of Traditional (1-ticket) vs Two-Ticket Schemes\n",
            "Based on 500 iterations\n",
            "\n",
            "       test_accuracy_1ticket  test_accuracy_2ticket  test_accuracy_improvement  test_tpr_1ticket  test_tpr_2ticket  tpr_improvement  test_disparity_1ticket  test_disparity_2_ticket  disparity_decrease_2_1  test_fnr_1ticket  test_fnr_2ticket\n",
            "count             500.000000             500.000000                 500.000000        500.000000        500.000000       500.000000              500.000000               500.000000              500.000000        500.000000        500.000000\n",
            "mean                0.514200               0.512600                  -0.001600          0.028400          0.025200        -0.003200                0.046747                -0.059156                0.105904          0.971600          0.974800\n",
            "std                 0.024349               0.023573                   0.034703          0.048698          0.047146         0.069406                0.079261                 0.108096                0.131345          0.048698          0.047146\n",
            "min                 0.500000               0.500000                  -0.133333          0.000000          0.000000        -0.266667                0.000000                -0.500000                0.000000          0.733333          0.733333\n",
            "25%                 0.500000               0.500000                  -0.033333          0.000000          0.000000        -0.066667                0.000000                -0.125000                0.000000          0.933333          0.933333\n",
            "50%                 0.500000               0.500000                   0.000000          0.000000          0.000000         0.000000                0.000000                 0.000000                0.090909          1.000000          1.000000\n",
            "75%                 0.533333               0.533333                   0.000000          0.066667          0.066667         0.000000                0.100000                 0.000000                0.166667          1.000000          1.000000\n",
            "max                 0.633333               0.633333                   0.100000          0.266667          0.266667         0.200000                0.500000                 0.000000                0.535714          1.000000          1.000000\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "KEY INSIGHTS FOR Condition 1:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "TPR Improvement (mean): -0.0032 (-11.3% increase)\n",
            "Accuracy Improvement (mean): -0.0016\n",
            "Disparity Decrease (mean): 0.1059\n",
            "  - Traditional disparity: 0.0467\n",
            "  - Two-Ticket disparity: -0.0592\n",
            "\n",
            "Two-Ticket wins:\n",
            "  - Higher TPR: 110/500 iterations (22.0%)\n",
            "  - Higher Accuracy: 110/500 iterations (22.0%)\n",
            "  - Lower Disparity: 257/500 iterations (51.4%)\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "Condition 2: DETAILED STATISTICS\n",
            "====================================================================================================\n",
            "\n",
            "Comparison of Traditional (1-ticket) vs Two-Ticket Schemes\n",
            "Based on 500 iterations\n",
            "\n",
            "       test_accuracy_1ticket  test_accuracy_2ticket  test_accuracy_improvement  test_tpr_1ticket  test_tpr_2ticket  tpr_improvement  test_disparity_1ticket  test_disparity_2_ticket  disparity_decrease_2_1  test_fnr_1ticket  test_fnr_2ticket\n",
            "count             500.000000             500.000000                 500.000000        500.000000        500.000000       500.000000              500.000000               500.000000              500.000000        500.000000        500.000000\n",
            "mean                0.514200               0.514200                   0.000000          0.028400          0.028400         0.000000                0.046747                 0.046892               -0.000145          0.971600          0.971600\n",
            "std                 0.024349               0.024622                   0.014621          0.048698          0.049244         0.029241                0.079261                 0.080855                0.045258          0.048698          0.049244\n",
            "min                 0.500000               0.500000                  -0.066667          0.000000          0.000000        -0.133333                0.000000                 0.000000               -0.142857          0.733333          0.733333\n",
            "25%                 0.500000               0.500000                   0.000000          0.000000          0.000000         0.000000                0.000000                 0.000000                0.000000          0.933333          0.933333\n",
            "50%                 0.500000               0.500000                   0.000000          0.000000          0.000000         0.000000                0.000000                 0.000000                0.000000          1.000000          1.000000\n",
            "75%                 0.533333               0.533333                   0.000000          0.066667          0.066667         0.000000                0.100000                 0.100000                0.000000          1.000000          1.000000\n",
            "max                 0.633333               0.633333                   0.033333          0.266667          0.266667         0.066667                0.500000                 0.500000                0.222222          1.000000          1.000000\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "KEY INSIGHTS FOR Condition 2:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "TPR Improvement (mean): 0.0000 (0.0% increase)\n",
            "Accuracy Improvement (mean): 0.0000\n",
            "Disparity Decrease (mean): -0.0001\n",
            "  - Traditional disparity: 0.0467\n",
            "  - Two-Ticket disparity: 0.0469\n",
            "\n",
            "Two-Ticket wins:\n",
            "  - Higher TPR: 39/500 iterations (7.8%)\n",
            "  - Higher Accuracy: 39/500 iterations (7.8%)\n",
            "  - Lower Disparity: 30/500 iterations (6.0%)\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "Condition 3: DETAILED STATISTICS\n",
            "====================================================================================================\n",
            "\n",
            "Comparison of Traditional (1-ticket) vs Two-Ticket Schemes\n",
            "Based on 500 iterations\n",
            "\n",
            "       test_accuracy_1ticket  test_accuracy_2ticket  test_accuracy_improvement  test_tpr_1ticket  test_tpr_2ticket  tpr_improvement  test_disparity_1ticket  test_disparity_2_ticket  disparity_decrease_2_1  test_fnr_1ticket  test_fnr_2ticket\n",
            "count             500.000000             500.000000                 500.000000        500.000000        500.000000       500.000000              500.000000               500.000000              500.000000        500.000000        500.000000\n",
            "mean                0.514200               0.514200                   0.000000          0.028400          0.028400         0.000000                0.046747                 0.046892               -0.000145          0.971600          0.971600\n",
            "std                 0.024349               0.024622                   0.014621          0.048698          0.049244         0.029241                0.079261                 0.080855                0.045258          0.048698          0.049244\n",
            "min                 0.500000               0.500000                  -0.066667          0.000000          0.000000        -0.133333                0.000000                 0.000000               -0.142857          0.733333          0.733333\n",
            "25%                 0.500000               0.500000                   0.000000          0.000000          0.000000         0.000000                0.000000                 0.000000                0.000000          0.933333          0.933333\n",
            "50%                 0.500000               0.500000                   0.000000          0.000000          0.000000         0.000000                0.000000                 0.000000                0.000000          1.000000          1.000000\n",
            "75%                 0.533333               0.533333                   0.000000          0.066667          0.066667         0.000000                0.100000                 0.100000                0.000000          1.000000          1.000000\n",
            "max                 0.633333               0.633333                   0.033333          0.266667          0.266667         0.066667                0.500000                 0.500000                0.222222          1.000000          1.000000\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "KEY INSIGHTS FOR Condition 3:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "TPR Improvement (mean): 0.0000 (0.0% increase)\n",
            "Accuracy Improvement (mean): 0.0000\n",
            "Disparity Decrease (mean): -0.0001\n",
            "  - Traditional disparity: 0.0467\n",
            "  - Two-Ticket disparity: 0.0469\n",
            "\n",
            "Two-Ticket wins:\n",
            "  - Higher TPR: 39/500 iterations (7.8%)\n",
            "  - Higher Accuracy: 39/500 iterations (7.8%)\n",
            "  - Lower Disparity: 30/500 iterations (6.0%)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create detailed comparison for each condition\n",
        "for group_id in [1, 2, 3]:\n",
        "    condition_name = f\"Condition {group_id}\"\n",
        "    \n",
        "    # Filter data\n",
        "    trad_mask = (results_df['Condition'] == condition_name) & (results_df['Scheme'] == 'Traditional')\n",
        "    two_mask = (results_df['Condition'] == condition_name) & (results_df['Scheme'] == 'Two-Ticket')\n",
        "    \n",
        "    trad_data = results_df[trad_mask].reset_index(drop=True)\n",
        "    two_data = results_df[two_mask].reset_index(drop=True)\n",
        "    \n",
        "    # Create comparison DataFrame\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'test_accuracy_1ticket': trad_data['Accuracy'],\n",
        "        'test_accuracy_2ticket': two_data['Accuracy'],\n",
        "        'test_accuracy_improvement': two_data['Accuracy'] - trad_data['Accuracy'],\n",
        "        'test_tpr_1ticket': trad_data['TPR'],\n",
        "        'test_tpr_2ticket': two_data['TPR'],\n",
        "        'tpr_improvement': two_data['TPR'] - trad_data['TPR'],\n",
        "        'test_disparity_1ticket': trad_data['TPR_Disparity'],\n",
        "        'test_disparity_2_ticket': two_data['TPR_Disparity'],\n",
        "        'disparity_decrease_2_1': trad_data['TPR_Disparity'] - two_data['TPR_Disparity'],\n",
        "        'test_fnr_1ticket': trad_data['FNR'],\n",
        "        'test_fnr_2ticket': two_data['FNR']\n",
        "    })\n",
        "    \n",
        "    # Display statistics\n",
        "    print(\"=\"*100)\n",
        "    print(f\"{condition_name}: DETAILED STATISTICS\")\n",
        "    print(\"=\"*100)\n",
        "    print(f\"\\nComparison of Traditional (1-ticket) vs Two-Ticket Schemes\")\n",
        "    print(f\"Based on {len(comparison_df)} iterations\\n\")\n",
        "    \n",
        "    print(comparison_df.describe().to_string())\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(f\"\\nKEY INSIGHTS FOR {condition_name}:\")\n",
        "    print(\"-\"*100)\n",
        "    pct_increase = (comparison_df['tpr_improvement'].mean()/comparison_df['test_tpr_1ticket'].mean()*100) if comparison_df['test_tpr_1ticket'].mean() > 0 else 0\n",
        "    print(f\"TPR Improvement (mean): {comparison_df['tpr_improvement'].mean():.4f} ({pct_increase:.1f}% increase)\")\n",
        "    print(f\"Accuracy Improvement (mean): {comparison_df['test_accuracy_improvement'].mean():.4f}\")\n",
        "    print(f\"Disparity Decrease (mean): {comparison_df['disparity_decrease_2_1'].mean():.4f}\")\n",
        "    print(f\"  - Traditional disparity: {comparison_df['test_disparity_1ticket'].mean():.4f}\")\n",
        "    print(f\"  - Two-Ticket disparity: {comparison_df['test_disparity_2_ticket'].mean():.4f}\")\n",
        "    \n",
        "    # Check how often two-ticket is better\n",
        "    tpr_better = (comparison_df['tpr_improvement'] > 0).sum()\n",
        "    acc_better = (comparison_df['test_accuracy_improvement'] > 0).sum()\n",
        "    disp_better = (comparison_df['disparity_decrease_2_1'] > 0).sum()\n",
        "    \n",
        "    print(f\"\\nTwo-Ticket wins:\")\n",
        "    print(f\"  - Higher TPR: {tpr_better}/{len(comparison_df)} iterations ({tpr_better/len(comparison_df)*100:.1f}%)\")\n",
        "    print(f\"  - Higher Accuracy: {acc_better}/{len(comparison_df)} iterations ({acc_better/len(comparison_df)*100:.1f}%)\")\n",
        "    print(f\"  - Lower Disparity: {disp_better}/{len(comparison_df)} iterations ({disp_better/len(comparison_df)*100:.1f}%)\")\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
