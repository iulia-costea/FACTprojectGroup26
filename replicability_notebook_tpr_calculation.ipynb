{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoorDash PM Binary Classification Analysis (Table 1 Reproduction - Extension Data)\n",
    "\n",
    "This notebook reproduces the binary classification results from Section 8 of the paper for the DoorDash PM role.\n",
    "\n",
    "**Extension data: 50 qualified + 50 unqualified resumes**\n",
    "\n",
    "We will test three conditions:\n",
    "1. **U: No LLMs, P: GPT-4O** - Unprivileged group has no LLM access, Privileged group uses GPT-4o\n",
    "2. **U: GPT-3.5, P: GPT-4O** - Unprivileged uses GPT-3.5, Privileged uses GPT-4o  \n",
    "3. **U: GPT-4O-MINI, P: GPT-4O** - Unprivileged uses GPT-4o-mini, Privileged uses GPT-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Merge Qualified and Unqualified Resume Scores\n",
    "\n",
    "- **Qualified**: PM resumes (n=50) - these ARE qualified for the PM role\n",
    "- **Unqualified**: UX designer resumes (n=50) - these are NOT qualified for the PM role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized column names to: 'CV DoorDash PM Score'\n",
      "Qualified resumes: 50\n",
      "Unqualified resumes: 50\n",
      "\n",
      "Qualified sample:\n",
      "   Unnamed: 0  CV DoorDash PM Score  PM True Label\n",
      "0           0                81.061              1\n",
      "1           1                84.806              1\n",
      "2           2                81.328              1\n",
      "3           3                82.467              1\n",
      "4           4                81.239              1\n",
      "\n",
      "Unqualified sample:\n",
      "   Unnamed: 0  CV DoorDash PM Score  PM True Label\n",
      "0           0                78.009              0\n",
      "1           1                78.009              0\n",
      "2           2                77.359              0\n",
      "3           3                76.957              0\n",
      "4           4                78.456              0\n"
     ]
    }
   ],
   "source": [
    "# Load qualified resumes (PM resumes)\n",
    "qualified_original = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_Original_File_PM.csv')\n",
    "qualified_original['PM True Label'] = 1  # Qualified for PM role\n",
    "\n",
    "# Load unqualified resumes (UX resumes)\n",
    "unqualified_original = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoorDash_PM_Original_File_UX.csv')\n",
    "unqualified_original['PM True Label'] = 0  # Unqualified for PM role\n",
    "\n",
    "# IMPORTANT: Standardize column names - they differ between files\n",
    "qualified_cols = [col for col in qualified_original.columns if 'DoorDash' in col or 'Doordash' in col]\n",
    "unqualified_cols = [col for col in unqualified_original.columns if 'DoorDash' in col or 'Doordash' in col]\n",
    "\n",
    "if qualified_cols and unqualified_cols:\n",
    "    qualified_original.rename(columns={qualified_cols[0]: 'CV DoorDash PM Score'}, inplace=True)\n",
    "    unqualified_original.rename(columns={unqualified_cols[0]: 'CV DoorDash PM Score'}, inplace=True)\n",
    "    print(f\"Standardized column names to: 'CV DoorDash PM Score'\")\n",
    "\n",
    "# FIX: Keep only first 50 qualified resumes to get exactly 100 total\n",
    "qualified_original = qualified_original.head(50)\n",
    "\n",
    "print(f\"Qualified resumes: {len(qualified_original)}\")\n",
    "print(f\"Unqualified resumes: {len(unqualified_original)}\")\n",
    "print(\"\\nQualified sample:\")\n",
    "print(qualified_original.head())\n",
    "print(\"\\nUnqualified sample:\")\n",
    "print(unqualified_original.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load All Modified Resume Scores\n",
    "\n",
    "We need to load scores for:\n",
    "- GPT-3.5 modified\n",
    "- GPT-4o modified (once)\n",
    "- GPT-4o-mini modified\n",
    "- GPT-4o on GPT-3.5 (twice modified)\n",
    "- GPT-4o on GPT-4o-mini (twice modified)\n",
    "- GPT-4o on GPT-4o (twice modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All score files loaded successfully!\n",
      "Each file has 50 qualified and 50 unqualified resumes\n"
     ]
    }
   ],
   "source": [
    "# Load GPT-3.5 modified scores\n",
    "qualified_gpt35 = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt35turbo.csv').head(50)\n",
    "unqualified_gpt35 = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt35turbo.csv')\n",
    "\n",
    "# Load GPT-4o modified scores (once)\n",
    "qualified_gpt4o = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoorDash_PM_gpt4o.csv').head(50)\n",
    "unqualified_gpt4o = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4o.csv')\n",
    "\n",
    "# Load GPT-4o-mini modified scores\n",
    "qualified_gpt4omini = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt4omini.csv').head(50)\n",
    "unqualified_gpt4omini = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4omini.csv')\n",
    "\n",
    "# Load GPT-4o on GPT-3.5 scores\n",
    "qualified_gpt4o_on_gpt35 = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt4o_on_gpt35turbo.csv').head(50)\n",
    "unqualified_gpt4o_on_gpt35 = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4o_on_gpt35turbo.csv')\n",
    "\n",
    "# Load GPT-4o on GPT-4o-mini scores\n",
    "qualified_gpt4o_on_gpt4omini = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt4o_on_gpt4omini.csv').head(50)\n",
    "unqualified_gpt4o_on_gpt4omini = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4o_on_gpt4omini.csv')\n",
    "\n",
    "# Load GPT-4o on GPT-4o scores (twice modified)\n",
    "qualified_gpt4o_on_gpt4o = pd.read_csv('../tpr_calculation_files_extension/Qualified_PM/ScoresDoordash_PM_gpt4o_on_gpt4o.csv').head(50)\n",
    "unqualified_gpt4o_on_gpt4o = pd.read_csv('../tpr_calculation_files_extension/Unqualified_PM/ScoresDoordash_PM_gpt4o_on_gpt4o.csv')\n",
    "\n",
    "print(\"All score files loaded successfully!\")\n",
    "print(f\"Each file has {len(qualified_gpt35)} qualified and {len(unqualified_gpt35)} unqualified resumes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Merge All Scores into Single Dataframe\n",
    "\n",
    "We'll create one dataframe with all score columns for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataframe shape: (100, 9)\n",
      "Total resumes: 100\n",
      "\n",
      "Columns: ['Unnamed: 0', 'CV DoorDash PM Score', 'PM True Label', 'GPT-3.5 Score', 'GPT-4o Score', 'GPT-4o-mini Score', 'GPT-4o on GPT-3.5 Score', 'GPT-4o on GPT-4o-mini Score', 'GPT-4o on GPT-4o Score']\n",
      "\n",
      "Label distribution:\n",
      "PM True Label\n",
      "1    50\n",
      "0    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge qualified scores\n",
    "qualified_df = qualified_original.copy()\n",
    "qualified_df['GPT-3.5 Score'] = qualified_gpt35.iloc[:, 1].values\n",
    "qualified_df['GPT-4o Score'] = qualified_gpt4o.iloc[:, 1].values\n",
    "qualified_df['GPT-4o-mini Score'] = qualified_gpt4omini.iloc[:, 1].values\n",
    "qualified_df['GPT-4o on GPT-3.5 Score'] = qualified_gpt4o_on_gpt35.iloc[:, 1].values\n",
    "qualified_df['GPT-4o on GPT-4o-mini Score'] = qualified_gpt4o_on_gpt4omini.iloc[:, 1].values\n",
    "qualified_df['GPT-4o on GPT-4o Score'] = qualified_gpt4o_on_gpt4o.iloc[:, 1].values\n",
    "\n",
    "# Merge unqualified scores\n",
    "unqualified_df = unqualified_original.copy()\n",
    "unqualified_df['GPT-3.5 Score'] = unqualified_gpt35.iloc[:, 1].values\n",
    "unqualified_df['GPT-4o Score'] = unqualified_gpt4o.iloc[:, 1].values\n",
    "unqualified_df['GPT-4o-mini Score'] = unqualified_gpt4omini.iloc[:, 1].values\n",
    "unqualified_df['GPT-4o on GPT-3.5 Score'] = unqualified_gpt4o_on_gpt35.iloc[:, 1].values\n",
    "unqualified_df['GPT-4o on GPT-4o-mini Score'] = unqualified_gpt4o_on_gpt4omini.iloc[:, 1].values\n",
    "unqualified_df['GPT-4o on GPT-4o Score'] = unqualified_gpt4o_on_gpt4o.iloc[:, 1].values\n",
    "\n",
    "# Combine qualified and unqualified\n",
    "df_combined = pd.concat([qualified_df, unqualified_df], ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataframe shape: {df_combined.shape}\")\n",
    "print(f\"Total resumes: {len(df_combined)}\")\n",
    "print(f\"\\nColumns: {df_combined.columns.tolist()}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_combined['PM True Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Randomly Assign \"Will Manipulate\" Groups\n",
    "\n",
    "Randomly assign 50 resumes to Privileged group (P, Will Manipulate=True) and 50 to Unprivileged group (U, Will Manipulate=False).\n",
    "\n",
    "This assignment is independent of whether the resume is qualified or unqualified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will Manipulate distribution:\n",
      "Will Manipulate\n",
      "True     50\n",
      "False    50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cross-tabulation of True Label vs Will Manipulate:\n",
      "Will Manipulate  False  True \n",
      "PM True Label                \n",
      "0                   30     20\n",
      "1                   20     30\n",
      "\n",
      "Sample of data with new column:\n",
      "   CV DoorDash PM Score  PM True Label  Will Manipulate\n",
      "0                81.061              1             True\n",
      "1                84.806              1            False\n",
      "2                81.328              1            False\n",
      "3                82.467              1            False\n",
      "4                81.239              1             True\n",
      "5                78.576              1             True\n",
      "6                81.196              1            False\n",
      "7                80.252              1             True\n",
      "8                84.576              1            False\n",
      "9                79.446              1             True\n"
     ]
    }
   ],
   "source": [
    "# Randomly assign Will Manipulate groups (50/50 split)\n",
    "np.random.seed(42)\n",
    "indices = np.arange(len(df_combined))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# First 50 get Will Manipulate = True, next 50 get False\n",
    "df_combined['Will Manipulate'] = False\n",
    "df_combined.loc[indices[:50], 'Will Manipulate'] = True\n",
    "\n",
    "# Verify the assignment\n",
    "print(\"Will Manipulate distribution:\")\n",
    "print(df_combined['Will Manipulate'].value_counts())\n",
    "print(\"\\nCross-tabulation of True Label vs Will Manipulate:\")\n",
    "print(pd.crosstab(df_combined['PM True Label'], df_combined['Will Manipulate']))\n",
    "print(\"\\nSample of data with new column:\")\n",
    "print(df_combined[['CV DoorDash PM Score', 'PM True Label', 'Will Manipulate']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Helper Functions\n",
    "\n",
    "These functions replicate the methodology from the paper:\n",
    "1. **Score mapping functions**: Map original and modified scores based on group assignment\n",
    "2. **Threshold calculation**: Find optimal threshold with No False Positives objective\n",
    "3. **Metrics calculation**: Calculate TPR, FNR, Accuracy, and Disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Function 1: Map input scores (Traditional 1-ticket scheme)\n",
    "def map_input_score(row, group, groups_dict):\n",
    "    \"\"\"\n",
    "    Maps the score that the applicant submits to the hiring system.\n",
    "    - If Will Manipulate = True (Privileged): returns max(original, privileged_LLM_score)\n",
    "    - If Will Manipulate = False (Unprivileged): returns max(original, unprivileged_LLM_score)\n",
    "    \"\"\"\n",
    "    if row['Will Manipulate']:\n",
    "        # Privileged group: choose best between original and their LLM (Input-B)\n",
    "        return max(row[groups_dict[group]['Input-B']], row[groups_dict[0]])\n",
    "    else:\n",
    "        # Unprivileged group: choose best between original and their LLM (Input-A)\n",
    "        return max(row[groups_dict[group]['Input-A']], row[groups_dict[0]])\n",
    "\n",
    "\n",
    "# Function 2: Map hirer scores (Two-ticket scheme)\n",
    "def map_hirer_score(row, group, groups_dict):\n",
    "    \"\"\"\n",
    "    Maps the score after the hirer applies their own LLM manipulation.\n",
    "    - If Will Manipulate = True: returns max(submitted, hirer_LLM_on_submitted) where submitted was already modified (Hirer-B)\n",
    "    - If Will Manipulate = False: returns max(submitted, hirer_LLM_on_submitted) where submitted was original (Hirer-A)\n",
    "    \"\"\"\n",
    "    if row['Will Manipulate']:\n",
    "        # Privileged: hirer applies LLM to already-modified resume (twice modified)\n",
    "        return max(row[groups_dict[group]['Input-B']], row[groups_dict[group]['Hirer-B']])\n",
    "    else:\n",
    "        # Unprivileged: hirer applies LLM to original resume (once modified by hirer)\n",
    "        return max(row[groups_dict[group]['Input-A']], row[groups_dict[group]['Hirer-A']])\n",
    "\n",
    "\n",
    "# Function 3: Calculate threshold with relaxed FPR constraint (MODIFIED FOR SMALL DATASETS)\n",
    "def set_threshold_min_fpr(scores, labels, target_fpr=0.05):\n",
    "    \"\"\"\n",
    "    Find threshold that maximizes TPR while keeping FPR around target (default 5%).\n",
    "    \n",
    "    NOTE: Changed from strict \"No False Positives\" (FPR=0) to allow 5% FPR.\n",
    "    With only 100 samples, strict FPR=0 sets threshold too high (>90), \n",
    "    causing nearly all candidates to be rejected (TPR ≈ 0).\n",
    "    \n",
    "    Allowing 5% FPR enables meaningful differentiation between conditions.\n",
    "    \"\"\"\n",
    "    scores = np.array(scores)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    \n",
    "    # Find the threshold where FPR is closest to target\n",
    "    idx = np.argmin(np.abs(fpr - target_fpr))\n",
    "    return thresholds[idx]\n",
    "\n",
    "\n",
    "# Function 4: Calculate disparity between groups\n",
    "def calculate_disparity(y_true, y_pred, y_manipulate_label):\n",
    "    \"\"\"\n",
    "    Calculate TPR disparity: TPR_privileged - TPR_unprivileged\n",
    "    \"\"\"\n",
    "    # Separate by manipulation group\n",
    "    y_true_privileged = [y_true[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == True]\n",
    "    y_pred_privileged = [y_pred[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == True]\n",
    "    \n",
    "    y_true_unprivileged = [y_true[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == False]\n",
    "    y_pred_unprivileged = [y_pred[i] for i in range(len(y_manipulate_label)) if y_manipulate_label[i] == False]\n",
    "    \n",
    "    # Calculate confusion matrices\n",
    "    tn_p, fp_p, fn_p, tp_p = confusion_matrix(y_true_privileged, y_pred_privileged).ravel()\n",
    "    tn_u, fp_u, fn_u, tp_u = confusion_matrix(y_true_unprivileged, y_pred_unprivileged).ravel()\n",
    "    \n",
    "    # Calculate TPRs\n",
    "    tpr_privileged = tp_p / (tp_p + fn_p) if (tp_p + fn_p) > 0 else 0\n",
    "    tpr_unprivileged = tp_u / (tp_u + fn_u) if (tp_u + fn_u) > 0 else 0\n",
    "    \n",
    "    return tpr_privileged - tpr_unprivileged\n",
    "\n",
    "\n",
    "# Function 5: Calculate TPR, FNR, and Accuracy\n",
    "def calculate_tpr_fnr_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate overall TPR, FNR, and Accuracy.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return tpr, fnr, accuracy\n",
    "\n",
    "\n",
    "print(\"Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Define Experimental Conditions\n",
    "\n",
    "We'll test three conditions from Table 1:\n",
    "1. **Condition 1**: Unprivileged (U) = No LLM, Privileged (P) = GPT-4o\n",
    "2. **Condition 2**: Unprivileged (U) = GPT-3.5, Privileged (P) = GPT-4o\n",
    "3. **Condition 3**: Unprivileged (U) = GPT-4o-mini, Privileged (P) = GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental conditions defined:\n",
      "\n",
      "Condition 1:\n",
      "  Unprivileged Input: CV DoorDash PM Score\n",
      "  Privileged Input: GPT-4o Score\n",
      "  Hirer on Unprivileged: GPT-4o Score\n",
      "  Hirer on Privileged: GPT-4o on GPT-4o Score\n",
      "\n",
      "Condition 2:\n",
      "  Unprivileged Input: GPT-3.5 Score\n",
      "  Privileged Input: GPT-4o Score\n",
      "  Hirer on Unprivileged: GPT-4o on GPT-3.5 Score\n",
      "  Hirer on Privileged: GPT-4o on GPT-4o Score\n",
      "\n",
      "Condition 3:\n",
      "  Unprivileged Input: GPT-4o-mini Score\n",
      "  Privileged Input: GPT-4o Score\n",
      "  Hirer on Unprivileged: GPT-4o on GPT-4o-mini Score\n",
      "  Hirer on Privileged: GPT-4o on GPT-4o Score\n"
     ]
    }
   ],
   "source": [
    "groups_doordash_pm = {\n",
    "    0: 'CV DoorDash PM Score',  # Baseline original score\n",
    "    \n",
    "    # Condition 1: U: No LLM, P: GPT-4o\n",
    "    1: {\n",
    "        'Input-A': 'CV DoorDash PM Score',           # Unprivileged submits original\n",
    "        'Input-B': 'GPT-4o Score',                 # Privileged submits GPT-4o modified\n",
    "        'Hirer-A': 'GPT-4o Score',                 # Hirer applies GPT-4o to original\n",
    "        'Hirer-B': 'GPT-4o on GPT-4o Score'        # Hirer applies GPT-4o to GPT-4o modified\n",
    "    },\n",
    "    \n",
    "    # Condition 2: U: GPT-3.5, P: GPT-4o\n",
    "    2: {\n",
    "        'Input-A': 'GPT-3.5 Score',                # Unprivileged submits GPT-3.5 modified\n",
    "        'Input-B': 'GPT-4o Score',                 # Privileged submits GPT-4o modified\n",
    "        'Hirer-A': 'GPT-4o on GPT-3.5 Score',      # Hirer applies GPT-4o to GPT-3.5 modified\n",
    "        'Hirer-B': 'GPT-4o on GPT-4o Score'        # Hirer applies GPT-4o to GPT-4o modified\n",
    "    },\n",
    "    \n",
    "    # Condition 3: U: GPT-4o-mini, P: GPT-4o\n",
    "    3: {\n",
    "        'Input-A': 'GPT-4o-mini Score',            # Unprivileged submits GPT-4o-mini modified\n",
    "        'Input-B': 'GPT-4o Score',                 # Privileged submits GPT-4o modified\n",
    "        'Hirer-A': 'GPT-4o on GPT-4o-mini Score',  # Hirer applies GPT-4o to GPT-4o-mini modified\n",
    "        'Hirer-B': 'GPT-4o on GPT-4o Score'        # Hirer applies GPT-4o to GPT-4o modified\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Experimental conditions defined:\")\n",
    "for group_id in [1, 2, 3]:\n",
    "    print(f\"\\nCondition {group_id}:\")\n",
    "    print(f\"  Unprivileged Input: {groups_doordash_pm[group_id]['Input-A']}\")\n",
    "    print(f\"  Privileged Input: {groups_doordash_pm[group_id]['Input-B']}\")\n",
    "    print(f\"  Hirer on Unprivileged: {groups_doordash_pm[group_id]['Hirer-A']}\")\n",
    "    print(f\"  Hirer on Privileged: {groups_doordash_pm[group_id]['Hirer-B']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Run 500-Iteration Experiment\n",
    "\n",
    "For each condition, we'll:\n",
    "1. Run 500 iterations with random 70/30 train-test splits\n",
    "2. Test both Traditional (1-ticket) and Two-ticket hiring schemes\n",
    "3. Calculate TPR, TPR Disparity, FNR, and Accuracy for each iteration\n",
    "4. Store results for statistical analysis\n",
    "\n",
    "**Note**: With 100 total resumes, test set will be ~30 resumes per iteration.\n",
    "\n",
    "**IMPORTANT**: Due to the small dataset (100 samples vs 520 in the original study), we use a **relaxed FPR constraint (5%)** instead of strict \"No False Positives\" (FPR=0%). With only 4 qualified resumes scoring >90, the strict constraint causes nearly all candidates to be rejected (TPR ≈ 0%), making conditions indistinguishable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments...\n",
      "Total iterations per condition: 500\n",
      "Train-test split: 70/30\n",
      "\n",
      "\n",
      "============================================================\n",
      "Running Condition 1\n",
      "============================================================\n",
      "  Iteration 100/500\n",
      "  Iteration 200/500\n",
      "  Iteration 300/500\n",
      "  Iteration 400/500\n",
      "  Iteration 500/500\n",
      "\n",
      "============================================================\n",
      "Running Condition 2\n",
      "============================================================\n",
      "  Iteration 100/500\n",
      "  Iteration 200/500\n",
      "  Iteration 300/500\n",
      "  Iteration 400/500\n",
      "  Iteration 500/500\n",
      "\n",
      "============================================================\n",
      "Running Condition 3\n",
      "============================================================\n",
      "  Iteration 100/500\n",
      "  Iteration 200/500\n",
      "  Iteration 300/500\n",
      "  Iteration 400/500\n",
      "  Iteration 500/500\n",
      "\n",
      "============================================================\n",
      "Experiment completed!\n",
      "Total results: 3000 rows\n",
      "  - 3 conditions × 2 schemes × 500 iterations\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize results storage\n",
    "results = {\n",
    "    'Condition': [],\n",
    "    'Scheme': [],\n",
    "    'Iteration': [],\n",
    "    'TPR': [],\n",
    "    'TPR_Disparity': [],\n",
    "    'FNR': [],\n",
    "    'Accuracy': []\n",
    "}\n",
    "\n",
    "num_iterations = 500\n",
    "test_size = 0.3\n",
    "\n",
    "print(\"Running experiments...\")\n",
    "print(f\"Total iterations per condition: {num_iterations}\")\n",
    "print(f\"Train-test split: {int((1-test_size)*100)}/{int(test_size*100)}\\n\")\n",
    "\n",
    "# Run experiments for each condition\n",
    "for group_id in [1, 2, 3]:\n",
    "    condition_name = f\"Condition {group_id}\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running {condition_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        if (iteration + 1) % 100 == 0:\n",
    "            print(f\"  Iteration {iteration + 1}/{num_iterations}\")\n",
    "        \n",
    "        # Split data\n",
    "        train_df, test_df = train_test_split(\n",
    "            df_combined, \n",
    "            test_size=test_size, \n",
    "            random_state=42 + iteration,\n",
    "            stratify=df_combined['PM True Label']\n",
    "        )\n",
    "        \n",
    "        # Get true labels\n",
    "        y_train = train_df['PM True Label'].values\n",
    "        y_test = test_df['PM True Label'].values\n",
    "        y_test_manipulate = test_df['Will Manipulate'].values\n",
    "        \n",
    "        # === Traditional Scheme (1-ticket) ===\n",
    "        train_df['Input Score'] = train_df.apply(\n",
    "            lambda row: map_input_score(row, group_id, groups_doordash_pm), axis=1\n",
    "        )\n",
    "        test_df['Input Score'] = test_df.apply(\n",
    "            lambda row: map_input_score(row, group_id, groups_doordash_pm), axis=1\n",
    "        )\n",
    "        \n",
    "        X_train_trad = train_df['Input Score'].values\n",
    "        X_test_trad = test_df['Input Score'].values\n",
    "        \n",
    "        # Find threshold and make predictions\n",
    "        threshold_trad = set_threshold_min_fpr(X_train_trad, y_train)\n",
    "        y_pred_trad = (X_test_trad >= threshold_trad).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tpr_trad, fnr_trad, acc_trad = calculate_tpr_fnr_accuracy(y_test, y_pred_trad)\n",
    "        disparity_trad = calculate_disparity(y_test, y_pred_trad, y_test_manipulate)\n",
    "        \n",
    "        # Store results\n",
    "        results['Condition'].append(condition_name)\n",
    "        results['Scheme'].append('Traditional')\n",
    "        results['Iteration'].append(iteration)\n",
    "        results['TPR'].append(tpr_trad)\n",
    "        results['TPR_Disparity'].append(disparity_trad)\n",
    "        results['FNR'].append(fnr_trad)\n",
    "        results['Accuracy'].append(acc_trad)\n",
    "        \n",
    "        # === Two-Ticket Scheme ===\n",
    "        train_df['Hirer Score'] = train_df.apply(\n",
    "            lambda row: map_hirer_score(row, group_id, groups_doordash_pm), axis=1\n",
    "        )\n",
    "        test_df['Hirer Score'] = test_df.apply(\n",
    "            lambda row: map_hirer_score(row, group_id, groups_doordash_pm), axis=1\n",
    "        )\n",
    "        \n",
    "        X_train_two = train_df['Hirer Score'].values\n",
    "        X_test_two = test_df['Hirer Score'].values\n",
    "        \n",
    "        # Find threshold and make predictions\n",
    "        threshold_two = set_threshold_min_fpr(X_train_two, y_train)\n",
    "        y_pred_two = (X_test_two >= threshold_two).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tpr_two, fnr_two, acc_two = calculate_tpr_fnr_accuracy(y_test, y_pred_two)\n",
    "        disparity_two = calculate_disparity(y_test, y_pred_two, y_test_manipulate)\n",
    "        \n",
    "        # Store results\n",
    "        results['Condition'].append(condition_name)\n",
    "        results['Scheme'].append('Two-Ticket')\n",
    "        results['Iteration'].append(iteration)\n",
    "        results['TPR'].append(tpr_two)\n",
    "        results['TPR_Disparity'].append(disparity_two)\n",
    "        results['FNR'].append(fnr_two)\n",
    "        results['Accuracy'].append(acc_two)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Experiment completed!\")\n",
    "print(f\"Total results: {len(results_df)} rows\")\n",
    "print(f\"  - 3 conditions × 2 schemes × {num_iterations} iterations\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Table 1 Results\n",
    "\n",
    "Calculate mean TPR and TPR Disparity with 95% confidence intervals for each condition and scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TABLE 1 RESULTS: DoorDash PM Binary Classification (Extension Data)\n",
      "================================================================================\n",
      "\n",
      "Role: DoorDash PM\n",
      "Qualified Resumes: 50 PM resumes\n",
      "Unqualified Resumes: 50 UX Designer resumes\n",
      "Iterations: 500\n",
      "\n",
      "Objective: No False Positives (maximize TPR subject to FPR ≈ 0)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Condition 1: Traditional\n",
      "  TPR: 0.4933 (95% CI: [0.4814, 0.5053])\n",
      "  TPR Disparity: 0.4872 (95% CI: [0.4692, 0.5051])\n",
      "\n",
      "Condition 1: Two-Ticket\n",
      "  TPR: 0.6141 (95% CI: [0.6026, 0.6256])\n",
      "  TPR Disparity: 0.0372 (95% CI: [0.0162, 0.0581])\n",
      "\n",
      "Condition 2: Traditional\n",
      "  TPR: 0.5064 (95% CI: [0.4948, 0.5180])\n",
      "  TPR Disparity: 0.3807 (95% CI: [0.3613, 0.4001])\n",
      "\n",
      "Condition 2: Two-Ticket\n",
      "  TPR: 0.3907 (95% CI: [0.3782, 0.4031])\n",
      "  TPR Disparity: 0.5044 (95% CI: [0.4885, 0.5204])\n",
      "\n",
      "Condition 3: Traditional\n",
      "  TPR: 0.5064 (95% CI: [0.4923, 0.5205])\n",
      "  TPR Disparity: 0.1832 (95% CI: [0.1603, 0.2060])\n",
      "\n",
      "Condition 3: Two-Ticket\n",
      "  TPR: 0.5393 (95% CI: [0.5273, 0.5514])\n",
      "  TPR Disparity: 0.1854 (95% CI: [0.1638, 0.2070])\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Formatted Table:\n",
      "  Condition      Scheme                     TPR           TPR Disparity\n",
      "Condition 1 Traditional 0.4933 [0.4814, 0.5053] 0.4872 [0.4692, 0.5051]\n",
      "Condition 1  Two-Ticket 0.6141 [0.6026, 0.6256] 0.0372 [0.0162, 0.0581]\n",
      "Condition 2 Traditional 0.5064 [0.4948, 0.5180] 0.3807 [0.3613, 0.4001]\n",
      "Condition 2  Two-Ticket 0.3907 [0.3782, 0.4031] 0.5044 [0.4885, 0.5204]\n",
      "Condition 3 Traditional 0.5064 [0.4923, 0.5205] 0.1832 [0.1603, 0.2060]\n",
      "Condition 3  Two-Ticket 0.5393 [0.5273, 0.5514] 0.1854 [0.1638, 0.2070]\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics for each condition and scheme\n",
    "table1_results = []\n",
    "\n",
    "for condition in ['Condition 1', 'Condition 2', 'Condition 3']:\n",
    "    for scheme in ['Traditional', 'Two-Ticket']:\n",
    "        # Filter results for this condition and scheme\n",
    "        mask = (results_df['Condition'] == condition) & (results_df['Scheme'] == scheme)\n",
    "        subset = results_df[mask]\n",
    "        \n",
    "        # Calculate mean and 95% CI for TPR\n",
    "        tpr_values = subset['TPR'].values\n",
    "        tpr_mean = np.mean(tpr_values)\n",
    "        tpr_ci = stats.t.interval(0.95, len(tpr_values)-1, \n",
    "                                   loc=tpr_mean, \n",
    "                                   scale=stats.sem(tpr_values))\n",
    "        \n",
    "        # Calculate mean and 95% CI for TPR Disparity\n",
    "        disparity_values = subset['TPR_Disparity'].values\n",
    "        disparity_mean = np.mean(disparity_values)\n",
    "        disparity_ci = stats.t.interval(0.95, len(disparity_values)-1,\n",
    "                                        loc=disparity_mean,\n",
    "                                        scale=stats.sem(disparity_values))\n",
    "        \n",
    "        # Store results\n",
    "        table1_results.append({\n",
    "            'Condition': condition,\n",
    "            'Scheme': scheme,\n",
    "            'TPR_Mean': tpr_mean,\n",
    "            'TPR_CI_Lower': tpr_ci[0],\n",
    "            'TPR_CI_Upper': tpr_ci[1],\n",
    "            'TPR_Disparity_Mean': disparity_mean,\n",
    "            'TPR_Disparity_CI_Lower': disparity_ci[0],\n",
    "            'TPR_Disparity_CI_Upper': disparity_ci[1]\n",
    "        })\n",
    "\n",
    "# Create summary table\n",
    "table1_df = pd.DataFrame(table1_results)\n",
    "\n",
    "# Format for display\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE 1 RESULTS: DoorDash PM Binary Classification (Extension Data)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nRole: DoorDash PM\")\n",
    "print(f\"Qualified Resumes: 50 PM resumes\")\n",
    "print(f\"Unqualified Resumes: 50 UX Designer resumes\")\n",
    "print(f\"Iterations: {num_iterations}\")\n",
    "print(f\"\\nObjective: No False Positives (maximize TPR subject to FPR ≈ 0)\")\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "\n",
    "for _, row in table1_df.iterrows():\n",
    "    print(f\"\\n{row['Condition']}: {row['Scheme']}\")\n",
    "    print(f\"  TPR: {row['TPR_Mean']:.4f} (95% CI: [{row['TPR_CI_Lower']:.4f}, {row['TPR_CI_Upper']:.4f}])\")\n",
    "    print(f\"  TPR Disparity: {row['TPR_Disparity_Mean']:.4f} (95% CI: [{row['TPR_Disparity_CI_Lower']:.4f}, {row['TPR_Disparity_CI_Upper']:.4f}])\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Display as formatted DataFrame\n",
    "print(\"\\n\\nFormatted Table:\")\n",
    "display_df = table1_df.copy()\n",
    "display_df['TPR'] = display_df.apply(\n",
    "    lambda row: f\"{row['TPR_Mean']:.4f} [{row['TPR_CI_Lower']:.4f}, {row['TPR_CI_Upper']:.4f}]\", \n",
    "    axis=1\n",
    ")\n",
    "display_df['TPR Disparity'] = display_df.apply(\n",
    "    lambda row: f\"{row['TPR_Disparity_Mean']:.4f} [{row['TPR_Disparity_CI_Lower']:.4f}, {row['TPR_Disparity_CI_Upper']:.4f}]\",\n",
    "    axis=1\n",
    ")\n",
    "print(display_df[['Condition', 'Scheme', 'TPR', 'TPR Disparity']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Detailed Statistics Table\n",
    "\n",
    "Generate comprehensive statistics comparing Traditional (1-ticket) vs Two-Ticket schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Condition 1: DETAILED STATISTICS\n",
      "====================================================================================================\n",
      "\n",
      "Comparison of Traditional (1-ticket) vs Two-Ticket Schemes\n",
      "Based on 500 iterations\n",
      "\n",
      "       test_accuracy_1ticket  test_accuracy_2ticket  test_accuracy_improvement  test_tpr_1ticket  test_tpr_2ticket  tpr_improvement  test_disparity_1ticket  test_disparity_2_ticket  disparity_decrease_2_1  test_fnr_1ticket  test_fnr_2ticket\n",
      "count             500.000000             500.000000                 500.000000        500.000000        500.000000       500.000000              500.000000               500.000000              500.000000        500.000000        500.000000\n",
      "mean                0.723933               0.783667                   0.059733          0.493333          0.614133         0.120800                0.487188                 0.037155                0.450033          0.506667          0.385867\n",
      "std                 0.066252               0.059257                   0.063701          0.135717          0.130958         0.140500                0.204241                 0.238439                0.205214          0.135717          0.130958\n",
      "min                 0.533333               0.600000                  -0.133333          0.066667          0.200000        -0.333333               -0.071429                -0.818182               -0.153846          0.200000          0.066667\n",
      "25%                 0.666667               0.733333                   0.000000          0.400000          0.533333         0.000000                0.339286                -0.111111                0.300000          0.400000          0.266667\n",
      "50%                 0.733333               0.766667                   0.066667          0.533333          0.600000         0.133333                0.500000                 0.035714                0.444444          0.466667          0.400000\n",
      "75%                 0.766667               0.833333                   0.100000          0.600000          0.733333         0.200000                0.611111                 0.200000                0.590909          0.600000          0.466667\n",
      "max                 0.900000               0.933333                   0.266667          0.800000          0.933333         0.600000                1.000000                 0.833333                1.230769          0.933333          0.800000\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "KEY INSIGHTS FOR Condition 1:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TPR Improvement (mean): 0.1208 (24.5% increase)\n",
      "Accuracy Improvement (mean): 0.0597\n",
      "Disparity Decrease (mean): 0.4500\n",
      "  - Traditional disparity: 0.4872\n",
      "  - Two-Ticket disparity: 0.0372\n",
      "\n",
      "Two-Ticket wins:\n",
      "  - Higher TPR: 373/500 iterations (74.6%)\n",
      "  - Higher Accuracy: 370/500 iterations (74.0%)\n",
      "  - Lower Disparity: 486/500 iterations (97.2%)\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Condition 2: DETAILED STATISTICS\n",
      "====================================================================================================\n",
      "\n",
      "Comparison of Traditional (1-ticket) vs Two-Ticket Schemes\n",
      "Based on 500 iterations\n",
      "\n",
      "       test_accuracy_1ticket  test_accuracy_2ticket  test_accuracy_improvement  test_tpr_1ticket  test_tpr_2ticket  tpr_improvement  test_disparity_1ticket  test_disparity_2_ticket  disparity_decrease_2_1  test_fnr_1ticket  test_fnr_2ticket\n",
      "count             500.000000             500.000000                 500.000000        500.000000        500.000000       500.000000              500.000000               500.000000              500.000000        500.000000        500.000000\n",
      "mean                0.728133               0.673533                  -0.054600          0.506400          0.390667        -0.115733                0.380722                 0.504446               -0.123724          0.493600          0.609333\n",
      "std                 0.058020               0.061085                   0.052620          0.131598          0.141506         0.112348                0.220639                 0.181912                0.181605          0.131598          0.141506\n",
      "min                 0.533333               0.533333                  -0.200000          0.066667          0.066667        -0.533333               -0.214286                -0.204545               -0.666667          0.200000          0.200000\n",
      "25%                 0.700000               0.633333                  -0.100000          0.400000          0.266667        -0.200000                0.222222                 0.388889               -0.250000          0.400000          0.533333\n",
      "50%                 0.733333               0.666667                  -0.066667          0.533333          0.400000        -0.133333                0.394444                 0.500000               -0.125000          0.466667          0.600000\n",
      "75%                 0.766667               0.700000                  -0.025000          0.600000          0.466667        -0.066667                0.500000                 0.611111                0.000000          0.600000          0.733333\n",
      "max                 0.866667               0.800000                   0.100000          0.800000          0.800000         0.400000                1.000000                 1.000000                0.333333          0.933333          0.933333\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "KEY INSIGHTS FOR Condition 2:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TPR Improvement (mean): -0.1157 (-22.9% increase)\n",
      "Accuracy Improvement (mean): -0.0546\n",
      "Disparity Decrease (mean): -0.1237\n",
      "  - Traditional disparity: 0.3807\n",
      "  - Two-Ticket disparity: 0.5044\n",
      "\n",
      "Two-Ticket wins:\n",
      "  - Higher TPR: 34/500 iterations (6.8%)\n",
      "  - Higher Accuracy: 37/500 iterations (7.4%)\n",
      "  - Lower Disparity: 92/500 iterations (18.4%)\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Condition 3: DETAILED STATISTICS\n",
      "====================================================================================================\n",
      "\n",
      "Comparison of Traditional (1-ticket) vs Two-Ticket Schemes\n",
      "Based on 500 iterations\n",
      "\n",
      "       test_accuracy_1ticket  test_accuracy_2ticket  test_accuracy_improvement  test_tpr_1ticket  test_tpr_2ticket  tpr_improvement  test_disparity_1ticket  test_disparity_2_ticket  disparity_decrease_2_1  test_fnr_1ticket  test_fnr_2ticket\n",
      "count             500.000000             500.000000                 500.000000        500.000000        500.000000       500.000000              500.000000               500.000000              500.000000        500.000000        500.000000\n",
      "mean                0.731133               0.746867                   0.015733          0.506400          0.539333         0.032933                0.183151                 0.185407               -0.002256          0.493600          0.460667\n",
      "std                 0.073933               0.064882                   0.065430          0.160116          0.137508         0.149964                0.260026                 0.245873                0.214850          0.160116          0.137508\n",
      "min                 0.533333               0.500000                  -0.300000          0.066667          0.000000        -0.666667               -0.500000                -0.750000               -0.666667          0.000000          0.000000\n",
      "25%                 0.666667               0.700000                  -0.033333          0.400000          0.466667        -0.066667                0.000000                 0.043019               -0.125000          0.400000          0.400000\n",
      "50%                 0.733333               0.766667                   0.000000          0.533333          0.533333         0.000000                0.166667                 0.196429                0.000000          0.466667          0.466667\n",
      "75%                 0.800000               0.800000                   0.033333          0.600000          0.600000         0.066667                0.358766                 0.333333                0.055556          0.600000          0.533333\n",
      "max                 0.900000               0.900000                   0.233333          1.000000          1.000000         0.466667                0.833333                 0.833333                1.000000          0.933333          1.000000\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "KEY INSIGHTS FOR Condition 3:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TPR Improvement (mean): 0.0329 (6.5% increase)\n",
      "Accuracy Improvement (mean): 0.0157\n",
      "Disparity Decrease (mean): -0.0023\n",
      "  - Traditional disparity: 0.1832\n",
      "  - Two-Ticket disparity: 0.1854\n",
      "\n",
      "Two-Ticket wins:\n",
      "  - Higher TPR: 176/500 iterations (35.2%)\n",
      "  - Higher Accuracy: 179/500 iterations (35.8%)\n",
      "  - Lower Disparity: 140/500 iterations (28.0%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create detailed comparison for each condition\n",
    "for group_id in [1, 2, 3]:\n",
    "    condition_name = f\"Condition {group_id}\"\n",
    "    \n",
    "    # Filter data\n",
    "    trad_mask = (results_df['Condition'] == condition_name) & (results_df['Scheme'] == 'Traditional')\n",
    "    two_mask = (results_df['Condition'] == condition_name) & (results_df['Scheme'] == 'Two-Ticket')\n",
    "    \n",
    "    trad_data = results_df[trad_mask].reset_index(drop=True)\n",
    "    two_data = results_df[two_mask].reset_index(drop=True)\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'test_accuracy_1ticket': trad_data['Accuracy'],\n",
    "        'test_accuracy_2ticket': two_data['Accuracy'],\n",
    "        'test_accuracy_improvement': two_data['Accuracy'] - trad_data['Accuracy'],\n",
    "        'test_tpr_1ticket': trad_data['TPR'],\n",
    "        'test_tpr_2ticket': two_data['TPR'],\n",
    "        'tpr_improvement': two_data['TPR'] - trad_data['TPR'],\n",
    "        'test_disparity_1ticket': trad_data['TPR_Disparity'],\n",
    "        'test_disparity_2_ticket': two_data['TPR_Disparity'],\n",
    "        'disparity_decrease_2_1': trad_data['TPR_Disparity'] - two_data['TPR_Disparity'],\n",
    "        'test_fnr_1ticket': trad_data['FNR'],\n",
    "        'test_fnr_2ticket': two_data['FNR']\n",
    "    })\n",
    "    \n",
    "    # Display statistics\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{condition_name}: DETAILED STATISTICS\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\nComparison of Traditional (1-ticket) vs Two-Ticket Schemes\")\n",
    "    print(f\"Based on {len(comparison_df)} iterations\\n\")\n",
    "    \n",
    "    print(comparison_df.describe().to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"\\nKEY INSIGHTS FOR {condition_name}:\")\n",
    "    print(\"-\"*100)\n",
    "    pct_increase = (comparison_df['tpr_improvement'].mean()/comparison_df['test_tpr_1ticket'].mean()*100) if comparison_df['test_tpr_1ticket'].mean() > 0 else 0\n",
    "    print(f\"TPR Improvement (mean): {comparison_df['tpr_improvement'].mean():.4f} ({pct_increase:.1f}% increase)\")\n",
    "    print(f\"Accuracy Improvement (mean): {comparison_df['test_accuracy_improvement'].mean():.4f}\")\n",
    "    print(f\"Disparity Decrease (mean): {comparison_df['disparity_decrease_2_1'].mean():.4f}\")\n",
    "    print(f\"  - Traditional disparity: {comparison_df['test_disparity_1ticket'].mean():.4f}\")\n",
    "    print(f\"  - Two-Ticket disparity: {comparison_df['test_disparity_2_ticket'].mean():.4f}\")\n",
    "    \n",
    "    # Check how often two-ticket is better\n",
    "    tpr_better = (comparison_df['tpr_improvement'] > 0).sum()\n",
    "    acc_better = (comparison_df['test_accuracy_improvement'] > 0).sum()\n",
    "    disp_better = (comparison_df['disparity_decrease_2_1'] > 0).sum()\n",
    "    \n",
    "    print(f\"\\nTwo-Ticket wins:\")\n",
    "    print(f\"  - Higher TPR: {tpr_better}/{len(comparison_df)} iterations ({tpr_better/len(comparison_df)*100:.1f}%)\")\n",
    "    print(f\"  - Higher Accuracy: {acc_better}/{len(comparison_df)} iterations ({acc_better/len(comparison_df)*100:.1f}%)\")\n",
    "    print(f\"  - Lower Disparity: {disp_better}/{len(comparison_df)} iterations ({disp_better/len(comparison_df)*100:.1f}%)\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
